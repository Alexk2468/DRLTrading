{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Getting Started - Load Python Packages\n",
    "# 1.1. Import Packages\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.use(\"Agg\")\n",
    "import sys\n",
    "\n",
    "os.chdir(\"../../../DRLTrading\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pyfolio as pf\n",
    "\n",
    "from meta import config\n",
    "from meta import config_tickers\n",
    "from meta.data_processor import DataProcessor\n",
    "sys.path.append(\"C:\\python310\\lib\\site-packages\")\n",
    "from meta.env_portfolio_allocation.env_portfolio_yahoofinance import (\n",
    "    StockPortfolioEnv,\n",
    ")\n",
    "from agents.stablebaselines3_models import DRLAgent\n",
    "from plot import (\n",
    "    backtest_stats,\n",
    "    backtest_plot,\n",
    "    get_daily_return,\n",
    "    get_baseline,\n",
    "    convert_daily_return_to_pyfolio_ts,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2. Create Folders\n",
    "import main\n",
    "\n",
    "main.check_and_make_directories(\n",
    "    [\n",
    "        config.DATA_SAVE_DIR,\n",
    "        config.TRAINED_MODEL_DIR,\n",
    "        config.TENSORBOARD_LOG_DIR,\n",
    "        config.RESULTS_DIR,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOW_30_TICKER: ['AXP', 'AMGN', 'AAPL', 'BA', 'CAT', 'CSCO', 'CVX', 'GS', 'HD', 'HON', 'IBM', 'INTC', 'JNJ', 'KO', 'JPM', 'MCD', 'MMM', 'MRK', 'MSFT', 'NKE', 'PG', 'TRV', 'UNH', 'CRM', 'VZ', 'V', 'WBA', 'WMT', 'DIS', 'DOW']\n",
      "yahoofinance successfully connected\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- DOW: Data doesn't exist for startDate = 1230786000, endDate = 1546318800\n",
      "Shape of DataFrame:  (72964, 9)\n",
      "Clean data for AAPL\n",
      "Data clean for AAPL is finished.\n",
      "Clean data for AMGN\n",
      "Data clean for AMGN is finished.\n",
      "Clean data for AXP\n",
      "Data clean for AXP is finished.\n",
      "Clean data for BA\n",
      "Data clean for BA is finished.\n",
      "Clean data for CAT\n",
      "Data clean for CAT is finished.\n",
      "Clean data for CRM\n",
      "Data clean for CRM is finished.\n",
      "Clean data for CSCO\n",
      "Data clean for CSCO is finished.\n",
      "Clean data for CVX\n",
      "Data clean for CVX is finished.\n",
      "Clean data for DIS\n",
      "Data clean for DIS is finished.\n",
      "Clean data for GS\n",
      "Data clean for GS is finished.\n",
      "Clean data for HD\n",
      "Data clean for HD is finished.\n",
      "Clean data for HON\n",
      "Data clean for HON is finished.\n",
      "Clean data for IBM\n",
      "Data clean for IBM is finished.\n",
      "Clean data for INTC\n",
      "Data clean for INTC is finished.\n",
      "Clean data for JNJ\n",
      "Data clean for JNJ is finished.\n",
      "Clean data for JPM\n",
      "Data clean for JPM is finished.\n",
      "Clean data for KO\n",
      "Data clean for KO is finished.\n",
      "Clean data for MCD\n",
      "Data clean for MCD is finished.\n",
      "Clean data for MMM\n",
      "Data clean for MMM is finished.\n",
      "Clean data for MRK\n",
      "Data clean for MRK is finished.\n",
      "Clean data for MSFT\n",
      "Data clean for MSFT is finished.\n",
      "Clean data for NKE\n",
      "Data clean for NKE is finished.\n",
      "Clean data for PG\n",
      "Data clean for PG is finished.\n",
      "Clean data for TRV\n",
      "Data clean for TRV is finished.\n",
      "Clean data for UNH\n",
      "Data clean for UNH is finished.\n",
      "Clean data for V\n",
      "Data clean for V is finished.\n",
      "Clean data for VZ\n",
      "Data clean for VZ is finished.\n",
      "Clean data for WBA\n",
      "Data clean for WBA is finished.\n",
      "Clean data for WMT\n",
      "Data clean for WMT is finished.\n",
      "Data clean all finished!\n",
      "tech_indicator_list:  ['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma']\n",
      "indicator:  macd\n",
      "indicator:  boll_ub\n",
      "indicator:  boll_lb\n",
      "indicator:  rsi_30\n",
      "indicator:  cci_30\n",
      "indicator:  dx_30\n",
      "indicator:  close_30_sma\n",
      "indicator:  close_60_sma\n",
      "Succesfully add technical indicators\n",
      "Successfully transformed into array\n",
      "Shape of DataFrame:  (72906, 17)\n",
      "Shape of DataFrame:  (65598, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjusted_close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>cov_list</th>\n",
       "      <th>return_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>7.656429</td>\n",
       "      <td>7.686786</td>\n",
       "      <td>7.526786</td>\n",
       "      <td>7.534643</td>\n",
       "      <td>6.422665</td>\n",
       "      <td>552160000.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.151770</td>\n",
       "      <td>7.809801</td>\n",
       "      <td>6.634520</td>\n",
       "      <td>59.459729</td>\n",
       "      <td>119.669328</td>\n",
       "      <td>25.355894</td>\n",
       "      <td>7.180202</td>\n",
       "      <td>7.115042</td>\n",
       "      <td>[[0.00043702812754458194, 0.000134165767139395...</td>\n",
       "      <td>tic             AAPL      AMGN       AXP      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>56.939999</td>\n",
       "      <td>57.389999</td>\n",
       "      <td>56.500000</td>\n",
       "      <td>56.790001</td>\n",
       "      <td>42.570049</td>\n",
       "      <td>6015100.0</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>0.271541</td>\n",
       "      <td>58.391582</td>\n",
       "      <td>54.840419</td>\n",
       "      <td>50.007936</td>\n",
       "      <td>27.581378</td>\n",
       "      <td>1.908627</td>\n",
       "      <td>56.658667</td>\n",
       "      <td>56.394500</td>\n",
       "      <td>[[0.00043702812754458194, 0.000134165767139395...</td>\n",
       "      <td>tic             AAPL      AMGN       AXP      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>41.230000</td>\n",
       "      <td>41.669998</td>\n",
       "      <td>41.169998</td>\n",
       "      <td>41.490002</td>\n",
       "      <td>34.263405</td>\n",
       "      <td>8399400.0</td>\n",
       "      <td>AXP</td>\n",
       "      <td>0.354226</td>\n",
       "      <td>41.997035</td>\n",
       "      <td>39.628965</td>\n",
       "      <td>58.194409</td>\n",
       "      <td>79.143497</td>\n",
       "      <td>20.617391</td>\n",
       "      <td>40.788000</td>\n",
       "      <td>39.015000</td>\n",
       "      <td>[[0.00043702812754458194, 0.000134165767139395...</td>\n",
       "      <td>tic             AAPL      AMGN       AXP      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>58.230000</td>\n",
       "      <td>59.990002</td>\n",
       "      <td>57.880001</td>\n",
       "      <td>59.779999</td>\n",
       "      <td>46.582798</td>\n",
       "      <td>8836500.0</td>\n",
       "      <td>BA</td>\n",
       "      <td>1.101808</td>\n",
       "      <td>58.219951</td>\n",
       "      <td>52.756048</td>\n",
       "      <td>65.109172</td>\n",
       "      <td>257.267429</td>\n",
       "      <td>40.596881</td>\n",
       "      <td>54.797333</td>\n",
       "      <td>52.651667</td>\n",
       "      <td>[[0.00043702812754458194, 0.000134165767139395...</td>\n",
       "      <td>tic             AAPL      AMGN       AXP      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>59.180000</td>\n",
       "      <td>59.930000</td>\n",
       "      <td>59.049999</td>\n",
       "      <td>59.430000</td>\n",
       "      <td>41.974724</td>\n",
       "      <td>4718800.0</td>\n",
       "      <td>CAT</td>\n",
       "      <td>0.283309</td>\n",
       "      <td>59.574505</td>\n",
       "      <td>56.181494</td>\n",
       "      <td>56.931953</td>\n",
       "      <td>152.077629</td>\n",
       "      <td>16.584805</td>\n",
       "      <td>58.042000</td>\n",
       "      <td>57.683000</td>\n",
       "      <td>[[0.00043702812754458194, 0.000134165767139395...</td>\n",
       "      <td>tic             AAPL      AMGN       AXP      ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       open       high        low      close  adjusted_close  \\\n",
       "0  2010-01-06   7.656429   7.686786   7.526786   7.534643        6.422665   \n",
       "1  2010-01-06  56.939999  57.389999  56.500000  56.790001       42.570049   \n",
       "2  2010-01-06  41.230000  41.669998  41.169998  41.490002       34.263405   \n",
       "3  2010-01-06  58.230000  59.990002  57.880001  59.779999       46.582798   \n",
       "4  2010-01-06  59.180000  59.930000  59.049999  59.430000       41.974724   \n",
       "\n",
       "        volume   tic      macd    boll_ub    boll_lb     rsi_30      cci_30  \\\n",
       "0  552160000.0  AAPL  0.151770   7.809801   6.634520  59.459729  119.669328   \n",
       "1    6015100.0  AMGN  0.271541  58.391582  54.840419  50.007936   27.581378   \n",
       "2    8399400.0   AXP  0.354226  41.997035  39.628965  58.194409   79.143497   \n",
       "3    8836500.0    BA  1.101808  58.219951  52.756048  65.109172  257.267429   \n",
       "4    4718800.0   CAT  0.283309  59.574505  56.181494  56.931953  152.077629   \n",
       "\n",
       "       dx_30  close_30_sma  close_60_sma  \\\n",
       "0  25.355894      7.180202      7.115042   \n",
       "1   1.908627     56.658667     56.394500   \n",
       "2  20.617391     40.788000     39.015000   \n",
       "3  40.596881     54.797333     52.651667   \n",
       "4  16.584805     58.042000     57.683000   \n",
       "\n",
       "                                            cov_list  \\\n",
       "0  [[0.00043702812754458194, 0.000134165767139395...   \n",
       "1  [[0.00043702812754458194, 0.000134165767139395...   \n",
       "2  [[0.00043702812754458194, 0.000134165767139395...   \n",
       "3  [[0.00043702812754458194, 0.000134165767139395...   \n",
       "4  [[0.00043702812754458194, 0.000134165767139395...   \n",
       "\n",
       "                                         return_list  \n",
       "0  tic             AAPL      AMGN       AXP      ...  \n",
       "1  tic             AAPL      AMGN       AXP      ...  \n",
       "2  tic             AAPL      AMGN       AXP      ...  \n",
       "3  tic             AAPL      AMGN       AXP      ...  \n",
       "4  tic             AAPL      AMGN       AXP      ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Download and Preprocess Data\n",
    "print(f\"DOW_30_TICKER: {config_tickers.DOW_30_TICKER}\")\n",
    "\n",
    "dp = DataProcessor(\n",
    "    data_source=\"yahoofinance\",\n",
    "    start_date=\"2009-01-01\",\n",
    "    end_date=\"2019-01-01\",\n",
    "    time_interval=\"1D\",\n",
    ")\n",
    "\n",
    "dp.run(\n",
    "    ticker_list=config_tickers.DOW_30_TICKER,\n",
    "    technical_indicator_list=config.INDICATORS,\n",
    "    if_vix=False,\n",
    ")\n",
    "df = dp.dataframe\n",
    "\n",
    "df.head()\n",
    "\n",
    "print(\"Shape of DataFrame: \", df.shape)\n",
    "\n",
    "# Add covariance matrix as states\n",
    "df.rename(columns={\"time\": \"date\"}, inplace=True)\n",
    "df = df.sort_values([\"date\", \"tic\"], ignore_index=True)\n",
    "df.index = df.date.factorize()[0]\n",
    "df.drop(columns=[\"index\"], inplace=True)\n",
    "\n",
    "cov_list = []\n",
    "return_list = []\n",
    "\n",
    "# look back is one year\n",
    "lookback = 252\n",
    "for i in range(lookback, len(df.index.unique())):\n",
    "    data_lookback = df.loc[i - lookback : i, :]\n",
    "    price_lookback = data_lookback.pivot_table(\n",
    "        index=\"date\", columns=\"tic\", values=\"close\"\n",
    "    ).dropna(axis=1)\n",
    "    return_lookback = price_lookback.pct_change().dropna()\n",
    "    return_list.append(return_lookback)\n",
    "\n",
    "    covs = return_lookback.cov().values\n",
    "    cov_list.append(covs)\n",
    "\n",
    "df_cov = pd.DataFrame(\n",
    "    {\n",
    "        \"date\": df.date.unique()[lookback:],\n",
    "        \"cov_list\": cov_list,\n",
    "        \"return_list\": return_list,\n",
    "    }\n",
    ")\n",
    "df = df.merge(df_cov, on=\"date\")\n",
    "df = df.sort_values([\"date\", \"tic\"]).reset_index(drop=True)\n",
    "print(\"Shape of DataFrame: \", df.shape)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 29, State Space: 29\n"
     ]
    }
   ],
   "source": [
    "# 4. Design Environment\n",
    "\n",
    "# Training data split: 2009-01-01 to 2018-01-01\n",
    "train = dp.data_split(df, \"2009-01-01\", \"2018-01-01\")\n",
    "\n",
    "train.head()\n",
    "\n",
    "# Environment for Portfolio Allocation\n",
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100,\n",
    "    \"initial_amount\": 1000000,\n",
    "    \"transaction_cost_pct\": 0.001,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": config.INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": 1e-4,\n",
    "}\n",
    "\n",
    "e_train_gym = StockPortfolioEnv(df=train, **env_kwargs)\n",
    "\n",
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "# print(type(env_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0002}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c\\a2c_2\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 193       |\n",
      "|    iterations         | 100       |\n",
      "|    time_elapsed       | 2         |\n",
      "|    total_timesteps    | 500       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.1     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 99        |\n",
      "|    policy_loss        | 1.4e+08   |\n",
      "|    reward             | 1211942.2 |\n",
      "|    std                | 0.998     |\n",
      "|    value_loss         | 1.49e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 178       |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 5         |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | 2.11e+08  |\n",
      "|    reward             | 1822040.6 |\n",
      "|    std                | 0.997     |\n",
      "|    value_loss         | 3.32e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 193       |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 7         |\n",
      "|    total_timesteps    | 1500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.1     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | 2.53e+08  |\n",
      "|    reward             | 2189284.2 |\n",
      "|    std                | 0.997     |\n",
      "|    value_loss         | 5.16e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 208       |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 9         |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | 3.46e+08  |\n",
      "|    reward             | 3001018.8 |\n",
      "|    std                | 0.996     |\n",
      "|    value_loss         | 9.41e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3027908.3291736846\n",
      "Sharpe:  1.0633594494601386\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 214       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 11        |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | 1.53e+08  |\n",
      "|    reward             | 1189663.5 |\n",
      "|    std                | 0.996     |\n",
      "|    value_loss         | 1.55e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 225       |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 13        |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41       |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | 2.28e+08  |\n",
      "|    reward             | 1801419.9 |\n",
      "|    std                | 0.996     |\n",
      "|    value_loss         | 3.45e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 233       |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 14        |\n",
      "|    total_timesteps    | 3500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | 2.66e+08  |\n",
      "|    reward             | 2282052.5 |\n",
      "|    std                | 0.995     |\n",
      "|    value_loss         | 5.47e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 239       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 16        |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | 3.6e+08   |\n",
      "|    reward             | 3020105.0 |\n",
      "|    std                | 0.995     |\n",
      "|    value_loss         | 9.41e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3098443.592147239\n",
      "Sharpe:  1.080490169073639\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 242       |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 18        |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | 1.26e+08  |\n",
      "|    reward             | 1109990.9 |\n",
      "|    std                | 0.995     |\n",
      "|    value_loss         | 1.39e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 247       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 20        |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | 2.04e+08  |\n",
      "|    reward             | 1759542.2 |\n",
      "|    std                | 0.994     |\n",
      "|    value_loss         | 3.24e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 249       |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 22        |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | 2.61e+08  |\n",
      "|    reward             | 2128623.2 |\n",
      "|    std                | 0.994     |\n",
      "|    value_loss         | 4.78e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 251       |\n",
      "|    iterations         | 1200      |\n",
      "|    time_elapsed       | 23        |\n",
      "|    total_timesteps    | 6000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 1199      |\n",
      "|    policy_loss        | 3.42e+08  |\n",
      "|    reward             | 2737678.5 |\n",
      "|    std                | 0.993     |\n",
      "|    value_loss         | 7.98e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2889063.3705931497\n",
      "Sharpe:  1.019830901520358\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 248       |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 26        |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | 1.46e+08  |\n",
      "|    reward             | 1219864.2 |\n",
      "|    std                | 0.993     |\n",
      "|    value_loss         | 1.59e+13  |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 249       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 28        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | 2.14e+08  |\n",
      "|    reward             | 1853078.9 |\n",
      "|    std                | 0.992     |\n",
      "|    value_loss         | 3.68e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 250       |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 29        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | 2.55e+08  |\n",
      "|    reward             | 2278509.0 |\n",
      "|    std                | 0.992     |\n",
      "|    value_loss         | 5.34e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 251       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 31        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | 3.54e+08  |\n",
      "|    reward             | 2977944.0 |\n",
      "|    std                | 0.992     |\n",
      "|    value_loss         | 9.29e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3136695.9406158137\n",
      "Sharpe:  1.0953380995073572\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 249       |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 34        |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | 1.45e+08  |\n",
      "|    reward             | 1168630.6 |\n",
      "|    std                | 0.992     |\n",
      "|    value_loss         | 1.37e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 251       |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 35        |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | 1.96e+08  |\n",
      "|    reward             | 1733035.6 |\n",
      "|    std                | 0.991     |\n",
      "|    value_loss         | 3.08e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 252       |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 37        |\n",
      "|    total_timesteps    | 9500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | 2.52e+08  |\n",
      "|    reward             | 2121745.5 |\n",
      "|    std                | 0.991     |\n",
      "|    value_loss         | 4.68e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 253       |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 39        |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | 3.28e+08  |\n",
      "|    reward             | 2884700.2 |\n",
      "|    std                | 0.99      |\n",
      "|    value_loss         | 8.84e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3074379.212577335\n",
      "Sharpe:  1.079062174285248\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 254       |\n",
      "|    iterations         | 2100      |\n",
      "|    time_elapsed       | 41        |\n",
      "|    total_timesteps    | 10500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 2099      |\n",
      "|    policy_loss        | 1.23e+08  |\n",
      "|    reward             | 1131955.9 |\n",
      "|    std                | 0.989     |\n",
      "|    value_loss         | 1.23e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 255       |\n",
      "|    iterations         | 2200      |\n",
      "|    time_elapsed       | 43        |\n",
      "|    total_timesteps    | 11000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 2199      |\n",
      "|    policy_loss        | 2.11e+08  |\n",
      "|    reward             | 1667613.1 |\n",
      "|    std                | 0.988     |\n",
      "|    value_loss         | 3.1e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 256       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 44        |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | 2.52e+08  |\n",
      "|    reward             | 2025842.9 |\n",
      "|    std                | 0.988     |\n",
      "|    value_loss         | 4.29e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 258       |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 46        |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | 3.43e+08  |\n",
      "|    reward             | 2680410.2 |\n",
      "|    std                | 0.988     |\n",
      "|    value_loss         | 7.68e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2965941.772997238\n",
      "Sharpe:  1.0405762442576736\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 256       |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 48        |\n",
      "|    total_timesteps    | 12500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | 1.32e+08  |\n",
      "|    reward             | 1060113.9 |\n",
      "|    std                | 0.987     |\n",
      "|    value_loss         | 1.26e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 258       |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 50        |\n",
      "|    total_timesteps    | 13000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | 1.94e+08  |\n",
      "|    reward             | 1659466.1 |\n",
      "|    std                | 0.987     |\n",
      "|    value_loss         | 2.87e+13  |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 260       |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 51        |\n",
      "|    total_timesteps    | 13500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 2699      |\n",
      "|    policy_loss        | 2.13e+08  |\n",
      "|    reward             | 1973230.6 |\n",
      "|    std                | 0.986     |\n",
      "|    value_loss         | 3.99e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 261       |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 53        |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | 3.05e+08  |\n",
      "|    reward             | 2582873.0 |\n",
      "|    std                | 0.986     |\n",
      "|    value_loss         | 6.95e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2884006.519955922\n",
      "Sharpe:  1.0105364303010207\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 261       |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 55        |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | 1.34e+08  |\n",
      "|    reward             | 1055502.2 |\n",
      "|    std                | 0.985     |\n",
      "|    value_loss         | 1.29e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 262       |\n",
      "|    iterations         | 3000      |\n",
      "|    time_elapsed       | 57        |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | 1.91e+08  |\n",
      "|    reward             | 1622819.2 |\n",
      "|    std                | 0.985     |\n",
      "|    value_loss         | 2.76e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 263       |\n",
      "|    iterations         | 3100      |\n",
      "|    time_elapsed       | 58        |\n",
      "|    total_timesteps    | 15500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 3099      |\n",
      "|    policy_loss        | 2.32e+08  |\n",
      "|    reward             | 1934561.8 |\n",
      "|    std                | 0.985     |\n",
      "|    value_loss         | 4.1e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 264       |\n",
      "|    iterations         | 3200      |\n",
      "|    time_elapsed       | 60        |\n",
      "|    total_timesteps    | 16000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 3199      |\n",
      "|    policy_loss        | 3.06e+08  |\n",
      "|    reward             | 2584849.8 |\n",
      "|    std                | 0.984     |\n",
      "|    value_loss         | 7.14e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2904475.66559221\n",
      "Sharpe:  1.016572551005658\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 264       |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 62        |\n",
      "|    total_timesteps    | 16500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | 1.39e+08  |\n",
      "|    reward             | 1095214.0 |\n",
      "|    std                | 0.984     |\n",
      "|    value_loss         | 1.29e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 264       |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 64        |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | 2.1e+08   |\n",
      "|    reward             | 1631502.4 |\n",
      "|    std                | 0.983     |\n",
      "|    value_loss         | 3.02e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 265       |\n",
      "|    iterations         | 3500      |\n",
      "|    time_elapsed       | 65        |\n",
      "|    total_timesteps    | 17500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | 2.39e+08  |\n",
      "|    reward             | 2141881.8 |\n",
      "|    std                | 0.983     |\n",
      "|    value_loss         | 4.86e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 67        |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | 3.23e+08  |\n",
      "|    reward             | 2642031.8 |\n",
      "|    std                | 0.983     |\n",
      "|    value_loss         | 7.56e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2951663.7881844956\n",
      "Sharpe:  1.032250147850641\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 69        |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | 1.36e+08  |\n",
      "|    reward             | 1056916.2 |\n",
      "|    std                | 0.982     |\n",
      "|    value_loss         | 1.38e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 267       |\n",
      "|    iterations         | 3800      |\n",
      "|    time_elapsed       | 71        |\n",
      "|    total_timesteps    | 19000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 3799      |\n",
      "|    policy_loss        | 2.01e+08  |\n",
      "|    reward             | 1593576.8 |\n",
      "|    std                | 0.982     |\n",
      "|    value_loss         | 2.71e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 267       |\n",
      "|    iterations         | 3900      |\n",
      "|    time_elapsed       | 72        |\n",
      "|    total_timesteps    | 19500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 3899      |\n",
      "|    policy_loss        | 2.34e+08  |\n",
      "|    reward             | 2053418.6 |\n",
      "|    std                | 0.982     |\n",
      "|    value_loss         | 4.45e+13  |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 267       |\n",
      "|    iterations         | 4000      |\n",
      "|    time_elapsed       | 74        |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | 2.99e+08  |\n",
      "|    reward             | 2480461.8 |\n",
      "|    std                | 0.982     |\n",
      "|    value_loss         | 6.46e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2810562.807004213\n",
      "Sharpe:  0.9936448349643041\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 4100      |\n",
      "|    time_elapsed       | 76        |\n",
      "|    total_timesteps    | 20500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 4099      |\n",
      "|    policy_loss        | 1.47e+08  |\n",
      "|    reward             | 1187906.5 |\n",
      "|    std                | 0.982     |\n",
      "|    value_loss         | 1.46e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 267       |\n",
      "|    iterations         | 4200      |\n",
      "|    time_elapsed       | 78        |\n",
      "|    total_timesteps    | 21000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 4199      |\n",
      "|    policy_loss        | 1.89e+08  |\n",
      "|    reward             | 1619775.4 |\n",
      "|    std                | 0.981     |\n",
      "|    value_loss         | 2.79e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 267       |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 80        |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | 2.37e+08  |\n",
      "|    reward             | 2124477.5 |\n",
      "|    std                | 0.98      |\n",
      "|    value_loss         | 4.52e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 268       |\n",
      "|    iterations         | 4400      |\n",
      "|    time_elapsed       | 81        |\n",
      "|    total_timesteps    | 22000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 4399      |\n",
      "|    policy_loss        | 3.06e+08  |\n",
      "|    reward             | 2509709.2 |\n",
      "|    std                | 0.981     |\n",
      "|    value_loss         | 6.77e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2841925.059403003\n",
      "Sharpe:  1.0050029257934754\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 267       |\n",
      "|    iterations         | 4500      |\n",
      "|    time_elapsed       | 84        |\n",
      "|    total_timesteps    | 22500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 4499      |\n",
      "|    policy_loss        | 1.32e+08  |\n",
      "|    reward             | 1225977.2 |\n",
      "|    std                | 0.98      |\n",
      "|    value_loss         | 1.48e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 268       |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 85        |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 2.38e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | 1.77e+08  |\n",
      "|    reward             | 1604289.8 |\n",
      "|    std                | 0.98      |\n",
      "|    value_loss         | 2.65e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 268       |\n",
      "|    iterations         | 4700      |\n",
      "|    time_elapsed       | 87        |\n",
      "|    total_timesteps    | 23500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 4699      |\n",
      "|    policy_loss        | 2.63e+08  |\n",
      "|    reward             | 2144982.0 |\n",
      "|    std                | 0.979     |\n",
      "|    value_loss         | 5.22e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 268       |\n",
      "|    iterations         | 4800      |\n",
      "|    time_elapsed       | 89        |\n",
      "|    total_timesteps    | 24000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 4799      |\n",
      "|    policy_loss        | 3.44e+08  |\n",
      "|    reward             | 2654044.0 |\n",
      "|    std                | 0.978     |\n",
      "|    value_loss         | 7.48e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3066034.4155337564\n",
      "Sharpe:  1.0762433549249235\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 268       |\n",
      "|    iterations         | 4900      |\n",
      "|    time_elapsed       | 91        |\n",
      "|    total_timesteps    | 24500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 4899      |\n",
      "|    policy_loss        | 1.4e+08   |\n",
      "|    reward             | 1205946.2 |\n",
      "|    std                | 0.978     |\n",
      "|    value_loss         | 1.52e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 268       |\n",
      "|    iterations         | 5000      |\n",
      "|    time_elapsed       | 93        |\n",
      "|    total_timesteps    | 25000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 4999      |\n",
      "|    policy_loss        | 2e+08     |\n",
      "|    reward             | 1751848.8 |\n",
      "|    std                | 0.977     |\n",
      "|    value_loss         | 3.28e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 268       |\n",
      "|    iterations         | 5100      |\n",
      "|    time_elapsed       | 94        |\n",
      "|    total_timesteps    | 25500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 5099      |\n",
      "|    policy_loss        | 2.71e+08  |\n",
      "|    reward             | 2335584.8 |\n",
      "|    std                | 0.977     |\n",
      "|    value_loss         | 5.89e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 269       |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 96        |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 5199      |\n",
      "|    policy_loss        | 3.59e+08  |\n",
      "|    reward             | 2872056.8 |\n",
      "|    std                | 0.977     |\n",
      "|    value_loss         | 8.68e+13  |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3330618.2938814075\n",
      "Sharpe:  1.1472301370767604\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 268       |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 98        |\n",
      "|    total_timesteps    | 26500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | 1.27e+08  |\n",
      "|    reward             | 1146367.0 |\n",
      "|    std                | 0.977     |\n",
      "|    value_loss         | 1.48e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 269       |\n",
      "|    iterations         | 5400      |\n",
      "|    time_elapsed       | 100       |\n",
      "|    total_timesteps    | 27000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 5399      |\n",
      "|    policy_loss        | 2e+08     |\n",
      "|    reward             | 1646907.5 |\n",
      "|    std                | 0.976     |\n",
      "|    value_loss         | 2.97e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 269       |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 102       |\n",
      "|    total_timesteps    | 27500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 5499      |\n",
      "|    policy_loss        | 2.54e+08  |\n",
      "|    reward             | 2247902.5 |\n",
      "|    std                | 0.976     |\n",
      "|    value_loss         | 5.52e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 269       |\n",
      "|    iterations         | 5600      |\n",
      "|    time_elapsed       | 103       |\n",
      "|    total_timesteps    | 28000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 5599      |\n",
      "|    policy_loss        | 3.32e+08  |\n",
      "|    reward             | 2645346.5 |\n",
      "|    std                | 0.976     |\n",
      "|    value_loss         | 7.51e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3077734.759745887\n",
      "Sharpe:  1.0783846081339146\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 269       |\n",
      "|    iterations         | 5700      |\n",
      "|    time_elapsed       | 105       |\n",
      "|    total_timesteps    | 28500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 5699      |\n",
      "|    policy_loss        | 1.42e+08  |\n",
      "|    reward             | 1227748.5 |\n",
      "|    std                | 0.976     |\n",
      "|    value_loss         | 1.64e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 269       |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 107       |\n",
      "|    total_timesteps    | 29000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | 1.99e+08  |\n",
      "|    reward             | 1706403.5 |\n",
      "|    std                | 0.976     |\n",
      "|    value_loss         | 2.92e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 269       |\n",
      "|    iterations         | 5900      |\n",
      "|    time_elapsed       | 109       |\n",
      "|    total_timesteps    | 29500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 5899      |\n",
      "|    policy_loss        | 2.6e+08   |\n",
      "|    reward             | 2249594.8 |\n",
      "|    std                | 0.976     |\n",
      "|    value_loss         | 5.32e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 269       |\n",
      "|    iterations         | 6000      |\n",
      "|    time_elapsed       | 111       |\n",
      "|    total_timesteps    | 30000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 5999      |\n",
      "|    policy_loss        | 3.2e+08   |\n",
      "|    reward             | 2805567.2 |\n",
      "|    std                | 0.975     |\n",
      "|    value_loss         | 8.34e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3291466.1871840456\n",
      "Sharpe:  1.135146962387688\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 269       |\n",
      "|    iterations         | 6100      |\n",
      "|    time_elapsed       | 113       |\n",
      "|    total_timesteps    | 30500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 6099      |\n",
      "|    policy_loss        | 1.54e+08  |\n",
      "|    reward             | 1267024.6 |\n",
      "|    std                | 0.975     |\n",
      "|    value_loss         | 1.7e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 269       |\n",
      "|    iterations         | 6200      |\n",
      "|    time_elapsed       | 115       |\n",
      "|    total_timesteps    | 31000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 6199      |\n",
      "|    policy_loss        | 2.07e+08  |\n",
      "|    reward             | 1639049.9 |\n",
      "|    std                | 0.975     |\n",
      "|    value_loss         | 2.78e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 269       |\n",
      "|    iterations         | 6300      |\n",
      "|    time_elapsed       | 116       |\n",
      "|    total_timesteps    | 31500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 6299      |\n",
      "|    policy_loss        | 2.56e+08  |\n",
      "|    reward             | 2165702.8 |\n",
      "|    std                | 0.974     |\n",
      "|    value_loss         | 4.87e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 269       |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 118       |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | 2.85e+08  |\n",
      "|    reward             | 2521955.5 |\n",
      "|    std                | 0.974     |\n",
      "|    value_loss         | 6.78e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2987982.738922906\n",
      "Sharpe:  1.0473206210132364\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 268       |\n",
      "|    iterations         | 6500      |\n",
      "|    time_elapsed       | 120       |\n",
      "|    total_timesteps    | 32500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 6499      |\n",
      "|    policy_loss        | 1.38e+08  |\n",
      "|    reward             | 1132990.0 |\n",
      "|    std                | 0.974     |\n",
      "|    value_loss         | 1.39e+13  |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 269       |\n",
      "|    iterations         | 6600      |\n",
      "|    time_elapsed       | 122       |\n",
      "|    total_timesteps    | 33000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 6599      |\n",
      "|    policy_loss        | 1.65e+08  |\n",
      "|    reward             | 1529980.9 |\n",
      "|    std                | 0.973     |\n",
      "|    value_loss         | 2.49e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 269       |\n",
      "|    iterations         | 6700      |\n",
      "|    time_elapsed       | 124       |\n",
      "|    total_timesteps    | 33500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 6699      |\n",
      "|    policy_loss        | 2.59e+08  |\n",
      "|    reward             | 2045622.2 |\n",
      "|    std                | 0.973     |\n",
      "|    value_loss         | 4.37e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 269       |\n",
      "|    iterations         | 6800      |\n",
      "|    time_elapsed       | 126       |\n",
      "|    total_timesteps    | 34000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 6799      |\n",
      "|    policy_loss        | 2.77e+08  |\n",
      "|    reward             | 2411375.0 |\n",
      "|    std                | 0.972     |\n",
      "|    value_loss         | 6.22e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2855166.9887897274\n",
      "Sharpe:  1.0165820750884405\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 268       |\n",
      "|    iterations         | 6900      |\n",
      "|    time_elapsed       | 128       |\n",
      "|    total_timesteps    | 34500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 6899      |\n",
      "|    policy_loss        | 1.45e+08  |\n",
      "|    reward             | 1170702.6 |\n",
      "|    std                | 0.972     |\n",
      "|    value_loss         | 1.41e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 268       |\n",
      "|    iterations         | 7000      |\n",
      "|    time_elapsed       | 130       |\n",
      "|    total_timesteps    | 35000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 6999      |\n",
      "|    policy_loss        | 1.87e+08  |\n",
      "|    reward             | 1599764.4 |\n",
      "|    std                | 0.972     |\n",
      "|    value_loss         | 2.63e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 268       |\n",
      "|    iterations         | 7100      |\n",
      "|    time_elapsed       | 132       |\n",
      "|    total_timesteps    | 35500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 7099      |\n",
      "|    policy_loss        | 2.57e+08  |\n",
      "|    reward             | 2164480.8 |\n",
      "|    std                | 0.972     |\n",
      "|    value_loss         | 5.13e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 268       |\n",
      "|    iterations         | 7200      |\n",
      "|    time_elapsed       | 134       |\n",
      "|    total_timesteps    | 36000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 7199      |\n",
      "|    policy_loss        | 3e+08     |\n",
      "|    reward             | 2569999.2 |\n",
      "|    std                | 0.971     |\n",
      "|    value_loss         | 7.17e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3022456.849462633\n",
      "Sharpe:  1.0592476039670933\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 267       |\n",
      "|    iterations         | 7300      |\n",
      "|    time_elapsed       | 136       |\n",
      "|    total_timesteps    | 36500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 7299      |\n",
      "|    policy_loss        | 1.43e+08  |\n",
      "|    reward             | 1153195.6 |\n",
      "|    std                | 0.97      |\n",
      "|    value_loss         | 1.52e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 267       |\n",
      "|    iterations         | 7400      |\n",
      "|    time_elapsed       | 138       |\n",
      "|    total_timesteps    | 37000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 7399      |\n",
      "|    policy_loss        | 1.73e+08  |\n",
      "|    reward             | 1575258.4 |\n",
      "|    std                | 0.969     |\n",
      "|    value_loss         | 2.61e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 267       |\n",
      "|    iterations         | 7500      |\n",
      "|    time_elapsed       | 140       |\n",
      "|    total_timesteps    | 37500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 7499      |\n",
      "|    policy_loss        | 2.71e+08  |\n",
      "|    reward             | 2152290.5 |\n",
      "|    std                | 0.969     |\n",
      "|    value_loss         | 5.3e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 267       |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 141       |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | 3.3e+08   |\n",
      "|    reward             | 2711438.2 |\n",
      "|    std                | 0.968     |\n",
      "|    value_loss         | 7.78e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3148362.7807460874\n",
      "Sharpe:  1.0993519392357998\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 267       |\n",
      "|    iterations         | 7700      |\n",
      "|    time_elapsed       | 144       |\n",
      "|    total_timesteps    | 38500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 7699      |\n",
      "|    policy_loss        | 1.52e+08  |\n",
      "|    reward             | 1196124.4 |\n",
      "|    std                | 0.968     |\n",
      "|    value_loss         | 1.5e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 7800      |\n",
      "|    time_elapsed       | 146       |\n",
      "|    total_timesteps    | 39000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 7799      |\n",
      "|    policy_loss        | 1.64e+08  |\n",
      "|    reward             | 1506575.5 |\n",
      "|    std                | 0.968     |\n",
      "|    value_loss         | 2.41e+13  |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 7900      |\n",
      "|    time_elapsed       | 148       |\n",
      "|    total_timesteps    | 39500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 7899      |\n",
      "|    policy_loss        | 2.43e+08  |\n",
      "|    reward             | 2196326.2 |\n",
      "|    std                | 0.967     |\n",
      "|    value_loss         | 5.02e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 8000      |\n",
      "|    time_elapsed       | 150       |\n",
      "|    total_timesteps    | 40000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 7999      |\n",
      "|    policy_loss        | 2.71e+08  |\n",
      "|    reward             | 2606916.2 |\n",
      "|    std                | 0.967     |\n",
      "|    value_loss         | 6.86e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3078563.0513262325\n",
      "Sharpe:  1.0790094616225554\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 8100      |\n",
      "|    time_elapsed       | 152       |\n",
      "|    total_timesteps    | 40500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 8099      |\n",
      "|    policy_loss        | 1.34e+08  |\n",
      "|    reward             | 1138486.4 |\n",
      "|    std                | 0.966     |\n",
      "|    value_loss         | 1.39e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 8200      |\n",
      "|    time_elapsed       | 154       |\n",
      "|    total_timesteps    | 41000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 8199      |\n",
      "|    policy_loss        | 1.64e+08  |\n",
      "|    reward             | 1410053.0 |\n",
      "|    std                | 0.966     |\n",
      "|    value_loss         | 2.07e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 8300      |\n",
      "|    time_elapsed       | 155       |\n",
      "|    total_timesteps    | 41500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 8299      |\n",
      "|    policy_loss        | 2.26e+08  |\n",
      "|    reward             | 1925199.5 |\n",
      "|    std                | 0.966     |\n",
      "|    value_loss         | 3.81e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 265       |\n",
      "|    iterations         | 8400      |\n",
      "|    time_elapsed       | 157       |\n",
      "|    total_timesteps    | 42000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 2.38e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 8399      |\n",
      "|    policy_loss        | 2.57e+08  |\n",
      "|    reward             | 2205861.5 |\n",
      "|    std                | 0.965     |\n",
      "|    value_loss         | 5.16e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2741869.1997040566\n",
      "Sharpe:  0.977954653839353\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 265       |\n",
      "|    iterations         | 8500      |\n",
      "|    time_elapsed       | 160       |\n",
      "|    total_timesteps    | 42500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 8499      |\n",
      "|    policy_loss        | 1.53e+08  |\n",
      "|    reward             | 1169018.8 |\n",
      "|    std                | 0.965     |\n",
      "|    value_loss         | 1.46e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 264       |\n",
      "|    iterations         | 8600      |\n",
      "|    time_elapsed       | 162       |\n",
      "|    total_timesteps    | 43000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 8599      |\n",
      "|    policy_loss        | 1.6e+08   |\n",
      "|    reward             | 1495758.5 |\n",
      "|    std                | 0.964     |\n",
      "|    value_loss         | 2.36e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 264       |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 164       |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | 2.44e+08  |\n",
      "|    reward             | 2180063.2 |\n",
      "|    std                | 0.964     |\n",
      "|    value_loss         | 4.98e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 264       |\n",
      "|    iterations         | 8800      |\n",
      "|    time_elapsed       | 166       |\n",
      "|    total_timesteps    | 44000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 8799      |\n",
      "|    policy_loss        | 2.86e+08  |\n",
      "|    reward             | 2468308.0 |\n",
      "|    std                | 0.964     |\n",
      "|    value_loss         | 6.49e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3092649.6703297407\n",
      "Sharpe:  1.0834230726160985\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 264       |\n",
      "|    iterations         | 8900      |\n",
      "|    time_elapsed       | 168       |\n",
      "|    total_timesteps    | 44500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 8899      |\n",
      "|    policy_loss        | 1.43e+08  |\n",
      "|    reward             | 1157592.5 |\n",
      "|    std                | 0.964     |\n",
      "|    value_loss         | 1.41e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 264       |\n",
      "|    iterations         | 9000      |\n",
      "|    time_elapsed       | 170       |\n",
      "|    total_timesteps    | 45000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 8999      |\n",
      "|    policy_loss        | 1.65e+08  |\n",
      "|    reward             | 1423752.9 |\n",
      "|    std                | 0.963     |\n",
      "|    value_loss         | 2.08e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 264       |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 172       |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | 2.44e+08  |\n",
      "|    reward             | 2061421.9 |\n",
      "|    std                | 0.963     |\n",
      "|    value_loss         | 4.86e+13  |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 264       |\n",
      "|    iterations         | 9200      |\n",
      "|    time_elapsed       | 174       |\n",
      "|    total_timesteps    | 46000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 9199      |\n",
      "|    policy_loss        | 2.9e+08   |\n",
      "|    reward             | 2388712.5 |\n",
      "|    std                | 0.963     |\n",
      "|    value_loss         | 6.15e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2968263.1077852733\n",
      "Sharpe:  1.0466556218647567\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 263       |\n",
      "|    iterations         | 9300      |\n",
      "|    time_elapsed       | 176       |\n",
      "|    total_timesteps    | 46500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 9299      |\n",
      "|    policy_loss        | 1.38e+08  |\n",
      "|    reward             | 1117718.6 |\n",
      "|    std                | 0.962     |\n",
      "|    value_loss         | 1.32e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 263       |\n",
      "|    iterations         | 9400      |\n",
      "|    time_elapsed       | 178       |\n",
      "|    total_timesteps    | 47000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 9399      |\n",
      "|    policy_loss        | 1.53e+08  |\n",
      "|    reward             | 1366255.6 |\n",
      "|    std                | 0.962     |\n",
      "|    value_loss         | 2e+13     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 263       |\n",
      "|    iterations         | 9500      |\n",
      "|    time_elapsed       | 180       |\n",
      "|    total_timesteps    | 47500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 9499      |\n",
      "|    policy_loss        | 2.4e+08   |\n",
      "|    reward             | 2053067.1 |\n",
      "|    std                | 0.962     |\n",
      "|    value_loss         | 4.41e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 263       |\n",
      "|    iterations         | 9600      |\n",
      "|    time_elapsed       | 182       |\n",
      "|    total_timesteps    | 48000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 9599      |\n",
      "|    policy_loss        | 2.64e+08  |\n",
      "|    reward             | 2256575.8 |\n",
      "|    std                | 0.962     |\n",
      "|    value_loss         | 5.07e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2805066.2343039494\n",
      "Sharpe:  0.9982128194660844\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 262       |\n",
      "|    iterations         | 9700      |\n",
      "|    time_elapsed       | 184       |\n",
      "|    total_timesteps    | 48500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 9699      |\n",
      "|    policy_loss        | 1.45e+08  |\n",
      "|    reward             | 1134338.0 |\n",
      "|    std                | 0.962     |\n",
      "|    value_loss         | 1.33e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 262       |\n",
      "|    iterations         | 9800      |\n",
      "|    time_elapsed       | 186       |\n",
      "|    total_timesteps    | 49000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 9799      |\n",
      "|    policy_loss        | 1.67e+08  |\n",
      "|    reward             | 1421414.9 |\n",
      "|    std                | 0.963     |\n",
      "|    value_loss         | 2.11e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 262       |\n",
      "|    iterations         | 9900      |\n",
      "|    time_elapsed       | 188       |\n",
      "|    total_timesteps    | 49500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 9899      |\n",
      "|    policy_loss        | 2.64e+08  |\n",
      "|    reward             | 2205764.2 |\n",
      "|    std                | 0.963     |\n",
      "|    value_loss         | 5.1e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 262       |\n",
      "|    iterations         | 10000     |\n",
      "|    time_elapsed       | 190       |\n",
      "|    total_timesteps    | 50000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 9999      |\n",
      "|    policy_loss        | 2.83e+08  |\n",
      "|    reward             | 2487909.5 |\n",
      "|    std                | 0.962     |\n",
      "|    value_loss         | 6.51e+13  |\n",
      "-------------------------------------\n",
      "{'n_steps': 2048, 'ent_coef': 0.005, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo\\ppo_2\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3012969.3305014246\n",
      "Sharpe:  1.0526145429561569\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    fps             | 249       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 8         |\n",
      "|    total_timesteps | 2048      |\n",
      "| train/             |           |\n",
      "|    reward          | 996152.44 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3280236.9731563423\n",
      "Sharpe:  1.1262991102658784\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 285       |\n",
      "|    iterations           | 2         |\n",
      "|    time_elapsed         | 14        |\n",
      "|    total_timesteps      | 4096      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.87e+14  |\n",
      "|    n_updates            | 10        |\n",
      "|    policy_gradient_loss | -5.51e-07 |\n",
      "|    reward               | 1080613.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.57e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2911976.905336838\n",
      "Sharpe:  1.0266762051638172\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 299       |\n",
      "|    iterations           | 3         |\n",
      "|    time_elapsed         | 20        |\n",
      "|    total_timesteps      | 6144      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 5.14e+14  |\n",
      "|    n_updates            | 20        |\n",
      "|    policy_gradient_loss | -6.77e-07 |\n",
      "|    reward               | 1028243.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.04e+15  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3158591.9567348026\n",
      "Sharpe:  1.096764883800627\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 294       |\n",
      "|    iterations           | 4         |\n",
      "|    time_elapsed         | 27        |\n",
      "|    total_timesteps      | 8192      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.27e+14  |\n",
      "|    n_updates            | 30        |\n",
      "|    policy_gradient_loss | -8.66e-07 |\n",
      "|    reward               | 1051433.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.2e+14   |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2939281.2267178237\n",
      "Sharpe:  1.0331311190184227\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 291       |\n",
      "|    iterations           | 5         |\n",
      "|    time_elapsed         | 35        |\n",
      "|    total_timesteps      | 10240     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 5.14e+14  |\n",
      "|    n_updates            | 40        |\n",
      "|    policy_gradient_loss | -7.53e-07 |\n",
      "|    reward               | 1045851.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.02e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3025775.832756439\n",
      "Sharpe:  1.060778589253395\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 284       |\n",
      "|    iterations           | 6         |\n",
      "|    time_elapsed         | 43        |\n",
      "|    total_timesteps      | 12288     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.73e+14  |\n",
      "|    n_updates            | 50        |\n",
      "|    policy_gradient_loss | -6.16e-07 |\n",
      "|    reward               | 1094880.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.86e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2780190.4723820365\n",
      "Sharpe:  0.9790663444109395\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 280       |\n",
      "|    iterations           | 7         |\n",
      "|    time_elapsed         | 51        |\n",
      "|    total_timesteps      | 14336     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.87e+14  |\n",
      "|    n_updates            | 60        |\n",
      "|    policy_gradient_loss | -6.84e-07 |\n",
      "|    reward               | 1139403.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.48e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3107467.426990271\n",
      "Sharpe:  1.08282361177031\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 280       |\n",
      "|    iterations           | 8         |\n",
      "|    time_elapsed         | 58        |\n",
      "|    total_timesteps      | 16384     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.07e+14  |\n",
      "|    n_updates            | 70        |\n",
      "|    policy_gradient_loss | -8.55e-07 |\n",
      "|    reward               | 1133276.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.29e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2979939.4872622164\n",
      "Sharpe:  1.0424234463620203\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 279       |\n",
      "|    iterations           | 9         |\n",
      "|    time_elapsed         | 65        |\n",
      "|    total_timesteps      | 18432     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.62e+14  |\n",
      "|    n_updates            | 80        |\n",
      "|    policy_gradient_loss | -6.75e-07 |\n",
      "|    reward               | 1220414.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.56e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2823009.876616278\n",
      "Sharpe:  0.9991669179306678\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 280       |\n",
      "|    iterations           | 10        |\n",
      "|    time_elapsed         | 72        |\n",
      "|    total_timesteps      | 20480     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.43e+14  |\n",
      "|    n_updates            | 90        |\n",
      "|    policy_gradient_loss | -7.62e-07 |\n",
      "|    reward               | 1162107.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.24e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3087633.9629903906\n",
      "Sharpe:  1.076050337503422\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 282       |\n",
      "|    iterations           | 11        |\n",
      "|    time_elapsed         | 79        |\n",
      "|    total_timesteps      | 22528     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.53e+14  |\n",
      "|    n_updates            | 100       |\n",
      "|    policy_gradient_loss | -6.53e-07 |\n",
      "|    reward               | 1137784.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.06e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2934267.1136743748\n",
      "Sharpe:  1.0314395046597264\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 284       |\n",
      "|    iterations           | 12        |\n",
      "|    time_elapsed         | 86        |\n",
      "|    total_timesteps      | 24576     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.68e+14  |\n",
      "|    n_updates            | 110       |\n",
      "|    policy_gradient_loss | -8.69e-07 |\n",
      "|    reward               | 1094590.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.55e+14  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2958651.01087671\n",
      "Sharpe:  1.0364649750248762\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 286       |\n",
      "|    iterations           | 13        |\n",
      "|    time_elapsed         | 93        |\n",
      "|    total_timesteps      | 26624     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.51e+14  |\n",
      "|    n_updates            | 120       |\n",
      "|    policy_gradient_loss | -4.89e-07 |\n",
      "|    reward               | 1150959.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.36e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2932038.7440752443\n",
      "Sharpe:  1.0287513050286325\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 288       |\n",
      "|    iterations           | 14        |\n",
      "|    time_elapsed         | 99        |\n",
      "|    total_timesteps      | 28672     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.87e+14  |\n",
      "|    n_updates            | 130       |\n",
      "|    policy_gradient_loss | -7.92e-07 |\n",
      "|    reward               | 1283907.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.22e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3151523.9470544285\n",
      "Sharpe:  1.101194235962227\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 289       |\n",
      "|    iterations           | 15        |\n",
      "|    time_elapsed         | 106       |\n",
      "|    total_timesteps      | 30720     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.47e+14  |\n",
      "|    n_updates            | 140       |\n",
      "|    policy_gradient_loss | -7.29e-07 |\n",
      "|    reward               | 1348623.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.83e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2900899.2878694264\n",
      "Sharpe:  1.025723621152364\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 291       |\n",
      "|    iterations           | 16        |\n",
      "|    time_elapsed         | 112       |\n",
      "|    total_timesteps      | 32768     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.6e+14   |\n",
      "|    n_updates            | 150       |\n",
      "|    policy_gradient_loss | -7.49e-07 |\n",
      "|    reward               | 1297011.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.56e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3009912.4923850284\n",
      "Sharpe:  1.054435082321739\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 293       |\n",
      "|    iterations           | 17        |\n",
      "|    time_elapsed         | 118       |\n",
      "|    total_timesteps      | 34816     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.53e+14  |\n",
      "|    n_updates            | 160       |\n",
      "|    policy_gradient_loss | -6.48e-07 |\n",
      "|    reward               | 1339321.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.99e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2927792.893899991\n",
      "Sharpe:  1.029884481966265\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 294       |\n",
      "|    iterations           | 18        |\n",
      "|    time_elapsed         | 125       |\n",
      "|    total_timesteps      | 36864     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 5.15e+14  |\n",
      "|    n_updates            | 170       |\n",
      "|    policy_gradient_loss | -6.28e-07 |\n",
      "|    reward               | 1359204.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.38e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3040454.302813381\n",
      "Sharpe:  1.0687461051163594\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 294       |\n",
      "|    iterations           | 19        |\n",
      "|    time_elapsed         | 131       |\n",
      "|    total_timesteps      | 38912     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.77e+14  |\n",
      "|    n_updates            | 180       |\n",
      "|    policy_gradient_loss | -7.84e-07 |\n",
      "|    reward               | 1451231.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.3e+14   |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3017480.5976224765\n",
      "Sharpe:  1.056555327466209\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 296       |\n",
      "|    iterations           | 20        |\n",
      "|    time_elapsed         | 138       |\n",
      "|    total_timesteps      | 40960     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.71e+14  |\n",
      "|    n_updates            | 190       |\n",
      "|    policy_gradient_loss | -7.98e-07 |\n",
      "|    reward               | 1312827.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.31e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2897188.3595592882\n",
      "Sharpe:  1.0158710928820698\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 298       |\n",
      "|    iterations           | 21        |\n",
      "|    time_elapsed         | 144       |\n",
      "|    total_timesteps      | 43008     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.52e+14  |\n",
      "|    n_updates            | 200       |\n",
      "|    policy_gradient_loss | -6.86e-07 |\n",
      "|    reward               | 1426000.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.17e+14  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2973192.773767874\n",
      "Sharpe:  1.04321683669573\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 298       |\n",
      "|    iterations           | 22        |\n",
      "|    time_elapsed         | 150       |\n",
      "|    total_timesteps      | 45056     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.17e+14  |\n",
      "|    n_updates            | 210       |\n",
      "|    policy_gradient_loss | -1.02e-06 |\n",
      "|    reward               | 1556995.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.8e+14   |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3040234.1285796356\n",
      "Sharpe:  1.0644419766803126\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 300       |\n",
      "|    iterations           | 23        |\n",
      "|    time_elapsed         | 156       |\n",
      "|    total_timesteps      | 47104     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.77e+14  |\n",
      "|    n_updates            | 220       |\n",
      "|    policy_gradient_loss | -8.55e-07 |\n",
      "|    reward               | 1690832.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.91e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3023500.732574984\n",
      "Sharpe:  1.0616185345593323\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 301       |\n",
      "|    iterations           | 24        |\n",
      "|    time_elapsed         | 163       |\n",
      "|    total_timesteps      | 49152     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.99e+14  |\n",
      "|    n_updates            | 230       |\n",
      "|    policy_gradient_loss | -6.73e-07 |\n",
      "|    reward               | 1685469.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.59e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2981297.6938143605\n",
      "Sharpe:  1.0520515059839792\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 299       |\n",
      "|    iterations           | 25        |\n",
      "|    time_elapsed         | 170       |\n",
      "|    total_timesteps      | 51200     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.63e+14  |\n",
      "|    n_updates            | 240       |\n",
      "|    policy_gradient_loss | -9.47e-07 |\n",
      "|    reward               | 1700749.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.65e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2860825.043065644\n",
      "Sharpe:  1.0123717326773953\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 297       |\n",
      "|    iterations           | 26        |\n",
      "|    time_elapsed         | 178       |\n",
      "|    total_timesteps      | 53248     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.7e+14   |\n",
      "|    n_updates            | 250       |\n",
      "|    policy_gradient_loss | -7.79e-07 |\n",
      "|    reward               | 1728706.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.19e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3024909.1688192817\n",
      "Sharpe:  1.0564094475705519\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 294       |\n",
      "|    iterations           | 27        |\n",
      "|    time_elapsed         | 187       |\n",
      "|    total_timesteps      | 55296     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.18e+14  |\n",
      "|    n_updates            | 260       |\n",
      "|    policy_gradient_loss | -6.97e-07 |\n",
      "|    reward               | 1858535.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.03e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3103008.318300286\n",
      "Sharpe:  1.0809828191829098\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 292       |\n",
      "|    iterations           | 28        |\n",
      "|    time_elapsed         | 195       |\n",
      "|    total_timesteps      | 57344     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.81e+14  |\n",
      "|    n_updates            | 270       |\n",
      "|    policy_gradient_loss | -8.2e-07  |\n",
      "|    reward               | 1734956.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.43e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2836094.5284459908\n",
      "Sharpe:  1.0031440465263117\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 292       |\n",
      "|    iterations           | 29        |\n",
      "|    time_elapsed         | 203       |\n",
      "|    total_timesteps      | 59392     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 5.04e+14  |\n",
      "|    n_updates            | 280       |\n",
      "|    policy_gradient_loss | -6.55e-07 |\n",
      "|    reward               | 1828287.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.53e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3024601.8046934614\n",
      "Sharpe:  1.0568811837503207\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 291       |\n",
      "|    iterations           | 30        |\n",
      "|    time_elapsed         | 210       |\n",
      "|    total_timesteps      | 61440     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.23e+14  |\n",
      "|    n_updates            | 290       |\n",
      "|    policy_gradient_loss | -6.86e-07 |\n",
      "|    reward               | 1992318.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.67e+14  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3270265.614047258\n",
      "Sharpe:  1.1286611072021393\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 291       |\n",
      "|    iterations           | 31        |\n",
      "|    time_elapsed         | 218       |\n",
      "|    total_timesteps      | 63488     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.5e+14   |\n",
      "|    n_updates            | 300       |\n",
      "|    policy_gradient_loss | -9.61e-07 |\n",
      "|    reward               | 2011958.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.54e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3188552.436611934\n",
      "Sharpe:  1.1080246114223635\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 289       |\n",
      "|    iterations           | 32        |\n",
      "|    time_elapsed         | 226       |\n",
      "|    total_timesteps      | 65536     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 5.45e+14  |\n",
      "|    n_updates            | 310       |\n",
      "|    policy_gradient_loss | -6.02e-07 |\n",
      "|    reward               | 2005471.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.03e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2885557.5030400744\n",
      "Sharpe:  1.016190233830965\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 289       |\n",
      "|    iterations           | 33        |\n",
      "|    time_elapsed         | 233       |\n",
      "|    total_timesteps      | 67584     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 5.11e+14  |\n",
      "|    n_updates            | 320       |\n",
      "|    policy_gradient_loss | -8.2e-07  |\n",
      "|    reward               | 2117394.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1e+15     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3047540.1287282957\n",
      "Sharpe:  1.0665393400346685\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 288       |\n",
      "|    iterations           | 34        |\n",
      "|    time_elapsed         | 241       |\n",
      "|    total_timesteps      | 69632     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.52e+14  |\n",
      "|    n_updates            | 330       |\n",
      "|    policy_gradient_loss | -7.14e-07 |\n",
      "|    reward               | 2081609.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.17e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3065314.878287839\n",
      "Sharpe:  1.0689665341018968\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 287       |\n",
      "|    iterations           | 35        |\n",
      "|    time_elapsed         | 249       |\n",
      "|    total_timesteps      | 71680     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.45e+14  |\n",
      "|    n_updates            | 340       |\n",
      "|    policy_gradient_loss | -7.78e-07 |\n",
      "|    reward               | 2192569.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.53e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2955144.925995883\n",
      "Sharpe:  1.0354793752109048\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 287       |\n",
      "|    iterations           | 36        |\n",
      "|    time_elapsed         | 256       |\n",
      "|    total_timesteps      | 73728     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.67e+14  |\n",
      "|    n_updates            | 350       |\n",
      "|    policy_gradient_loss | -5.41e-07 |\n",
      "|    reward               | 2035345.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.74e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2745248.130899244\n",
      "Sharpe:  0.9697940947451162\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 287       |\n",
      "|    iterations           | 37        |\n",
      "|    time_elapsed         | 263       |\n",
      "|    total_timesteps      | 75776     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.43e+14  |\n",
      "|    n_updates            | 360       |\n",
      "|    policy_gradient_loss | -6.25e-07 |\n",
      "|    reward               | 2211642.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9e+14     |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3058224.422818577\n",
      "Sharpe:  1.0663893654446008\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 287       |\n",
      "|    iterations           | 38        |\n",
      "|    time_elapsed         | 270       |\n",
      "|    total_timesteps      | 77824     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.44e+14  |\n",
      "|    n_updates            | 370       |\n",
      "|    policy_gradient_loss | -6.79e-07 |\n",
      "|    reward               | 2039310.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.77e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2825790.302576864\n",
      "Sharpe:  0.9991047406336984\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 287       |\n",
      "|    iterations           | 39        |\n",
      "|    time_elapsed         | 278       |\n",
      "|    total_timesteps      | 79872     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.27e+14  |\n",
      "|    n_updates            | 380       |\n",
      "|    policy_gradient_loss | -7.55e-07 |\n",
      "|    reward               | 2132255.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.13e+14  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3192913.9611749914\n",
      "Sharpe:  1.1051292522851703\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 287       |\n",
      "|    iterations           | 40        |\n",
      "|    time_elapsed         | 285       |\n",
      "|    total_timesteps      | 81920     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.9e+14   |\n",
      "|    n_updates            | 390       |\n",
      "|    policy_gradient_loss | -7.54e-07 |\n",
      "|    reward               | 2139684.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.46e+14  |\n",
      "---------------------------------------\n",
      "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg\\ddpg_2\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3024288.8233312806\n",
      "Sharpe:  1.049319289092322\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3089071.8059418513\n",
      "Sharpe:  1.0725363826217131\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3089071.8059418513\n",
      "Sharpe:  1.0725363826217131\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3089071.8059418513\n",
      "Sharpe:  1.0725363826217131\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 30        |\n",
      "|    time_elapsed    | 263       |\n",
      "|    total_timesteps | 8044      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -3.79e+07 |\n",
      "|    critic_loss     | 1.6e+12   |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 6033      |\n",
      "|    reward          | 3089071.8 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3089071.8059418513\n",
      "Sharpe:  1.0725363826217131\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3089071.8059418513\n",
      "Sharpe:  1.0725363826217131\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3089071.8059418513\n",
      "Sharpe:  1.0725363826217131\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3089071.8059418513\n",
      "Sharpe:  1.0725363826217131\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 25        |\n",
      "|    time_elapsed    | 620       |\n",
      "|    total_timesteps | 16088     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -8.38e+07 |\n",
      "|    critic_loss     | 8.02e+12  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 14077     |\n",
      "|    reward          | 3089071.8 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3089071.8059418513\n",
      "Sharpe:  1.0725363826217131\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3089071.8059418513\n",
      "Sharpe:  1.0725363826217131\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3089071.8059418513\n",
      "Sharpe:  1.0725363826217131\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3089071.8059418513\n",
      "Sharpe:  1.0725363826217131\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 23        |\n",
      "|    time_elapsed    | 1010      |\n",
      "|    total_timesteps | 24132     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.14e+08 |\n",
      "|    critic_loss     | 1.15e+13  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 22121     |\n",
      "|    reward          | 3089071.8 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3089071.8059418513\n",
      "Sharpe:  1.0725363826217131\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3089071.8059418513\n",
      "Sharpe:  1.0725363826217131\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3089071.8059418513\n",
      "Sharpe:  1.0725363826217131\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3089071.8059418513\n",
      "Sharpe:  1.0725363826217131\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 23        |\n",
      "|    time_elapsed    | 1360      |\n",
      "|    total_timesteps | 32176     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.35e+08 |\n",
      "|    critic_loss     | 1.23e+13  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 30165     |\n",
      "|    reward          | 3089071.8 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3089071.8059418513\n",
      "Sharpe:  1.0725363826217131\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3089071.8059418513\n",
      "Sharpe:  1.0725363826217131\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3089071.8059418513\n",
      "Sharpe:  1.0725363826217131\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3089071.8059418513\n",
      "Sharpe:  1.0725363826217131\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 20        |\n",
      "|    fps             | 23        |\n",
      "|    time_elapsed    | 1718      |\n",
      "|    total_timesteps | 40220     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.48e+08 |\n",
      "|    critic_loss     | 1.07e+13  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 38209     |\n",
      "|    reward          | 3089071.8 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3089071.8059418513\n",
      "Sharpe:  1.0725363826217131\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3089071.8059418513\n",
      "Sharpe:  1.0725363826217131\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3089071.8059418513\n",
      "Sharpe:  1.0725363826217131\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3089071.8059418513\n",
      "Sharpe:  1.0725363826217131\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 24        |\n",
      "|    fps             | 22        |\n",
      "|    time_elapsed    | 2117      |\n",
      "|    total_timesteps | 48264     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.57e+08 |\n",
      "|    critic_loss     | 9.27e+12  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 46253     |\n",
      "|    reward          | 3089071.8 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3089071.8059418513\n",
      "Sharpe:  1.0725363826217131\n",
      "=================================\n",
      "{'batch_size': 128, 'buffer_size': 100000, 'learning_rate': 0.0003, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/sac\\sac_2\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3022365.569983513\n",
      "Sharpe:  1.05818059507635\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3009589.1472369013\n",
      "Sharpe:  1.0548021524452875\n",
      "=================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3009595.111485344\n",
      "Sharpe:  1.054803211965448\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3009492.8403920573\n",
      "Sharpe:  1.0547738043034598\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 20        |\n",
      "|    time_elapsed    | 389       |\n",
      "|    total_timesteps | 8044      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -5.36e+07 |\n",
      "|    critic_loss     | 2.45e+11  |\n",
      "|    ent_coef        | 1.18      |\n",
      "|    ent_coef_loss   | -30.2     |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 7943      |\n",
      "|    reward          | 3009492.8 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3009534.051783207\n",
      "Sharpe:  1.054784219185059\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3009581.431688734\n",
      "Sharpe:  1.0548029901734852\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3009543.6667398415\n",
      "Sharpe:  1.0547914635446556\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3009582.910333813\n",
      "Sharpe:  1.0547954887393487\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 21        |\n",
      "|    time_elapsed    | 747       |\n",
      "|    total_timesteps | 16088     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -8.77e+07 |\n",
      "|    critic_loss     | 6.49e+11  |\n",
      "|    ent_coef        | 12        |\n",
      "|    ent_coef_loss   | -342      |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 15987     |\n",
      "|    reward          | 3009583.0 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3009544.6516455202\n",
      "Sharpe:  1.0547981342902188\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3009771.1666981713\n",
      "Sharpe:  1.054867048129537\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3010182.5154976235\n",
      "Sharpe:  1.0550088672091653\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3011378.394768427\n",
      "Sharpe:  1.0553853484609166\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 21        |\n",
      "|    time_elapsed    | 1129      |\n",
      "|    total_timesteps | 24132     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.17e+08 |\n",
      "|    critic_loss     | 1.97e+12  |\n",
      "|    ent_coef        | 115       |\n",
      "|    ent_coef_loss   | -370      |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 24031     |\n",
      "|    reward          | 3011378.5 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3010143.602316949\n",
      "Sharpe:  1.0550609232736128\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3015086.4529282046\n",
      "Sharpe:  1.0566055424840421\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3016582.6672753203\n",
      "Sharpe:  1.0569631751916795\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2997245.101987781\n",
      "Sharpe:  1.0514227592390732\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 21        |\n",
      "|    time_elapsed    | 1519      |\n",
      "|    total_timesteps | 32176     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.25e+08 |\n",
      "|    critic_loss     | 2.34e+12  |\n",
      "|    ent_coef        | 913       |\n",
      "|    ent_coef_loss   | -136      |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 32075     |\n",
      "|    reward          | 2997245.0 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2994054.908262884\n",
      "Sharpe:  1.0508087347935378\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3019006.518579574\n",
      "Sharpe:  1.0588211027237766\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3012803.743125903\n",
      "Sharpe:  1.0565938914030242\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3027788.5273495237\n",
      "Sharpe:  1.0615780781742479\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 20        |\n",
      "|    fps             | 21        |\n",
      "|    time_elapsed    | 1890      |\n",
      "|    total_timesteps | 40220     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.31e+08 |\n",
      "|    critic_loss     | 2.78e+12  |\n",
      "|    ent_coef        | 2.12e+03  |\n",
      "|    ent_coef_loss   | 3.08      |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 40119     |\n",
      "|    reward          | 3027788.5 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3011402.9150820374\n",
      "Sharpe:  1.0560087547581487\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2999652.5528120426\n",
      "Sharpe:  1.0528599325519152\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3009076.151128239\n",
      "Sharpe:  1.0548432468335245\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3040719.862324754\n",
      "Sharpe:  1.0652397592790583\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 24        |\n",
      "|    fps             | 20        |\n",
      "|    time_elapsed    | 2341      |\n",
      "|    total_timesteps | 48264     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.33e+08 |\n",
      "|    critic_loss     | 2.4e+12   |\n",
      "|    ent_coef        | 2.22e+03  |\n",
      "|    ent_coef_loss   | -6.14     |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 48163     |\n",
      "|    reward          | 3040719.8 |\n",
      "----------------------------------\n",
      "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/td3\\td3_2\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3115364.261279869\n",
      "Sharpe:  1.0810615904355565\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3010096.110252478\n",
      "Sharpe:  1.0423906295420917\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3010096.110252478\n",
      "Sharpe:  1.0423906295420917\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3010096.110252478\n",
      "Sharpe:  1.0423906295420917\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 29        |\n",
      "|    time_elapsed    | 268       |\n",
      "|    total_timesteps | 8044      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.99e+07 |\n",
      "|    critic_loss     | 8.3e+11   |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 6033      |\n",
      "|    reward          | 3010096.0 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3010096.110252478\n",
      "Sharpe:  1.0423906295420917\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3010096.110252478\n",
      "Sharpe:  1.0423906295420917\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3010096.110252478\n",
      "Sharpe:  1.0423906295420917\n",
      "=================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3010096.110252478\n",
      "Sharpe:  1.0423906295420917\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 25        |\n",
      "|    time_elapsed    | 621       |\n",
      "|    total_timesteps | 16088     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -4.83e+07 |\n",
      "|    critic_loss     | 4.14e+12  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 14077     |\n",
      "|    reward          | 3010096.0 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3010096.110252478\n",
      "Sharpe:  1.0423906295420917\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3010096.110252478\n",
      "Sharpe:  1.0423906295420917\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3010096.110252478\n",
      "Sharpe:  1.0423906295420917\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3010096.110252478\n",
      "Sharpe:  1.0423906295420917\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 24        |\n",
      "|    time_elapsed    | 975       |\n",
      "|    total_timesteps | 24132     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -7.14e+07 |\n",
      "|    critic_loss     | 1.03e+13  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 22121     |\n",
      "|    reward          | 3010096.0 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3010096.110252478\n",
      "Sharpe:  1.0423906295420917\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3010096.110252478\n",
      "Sharpe:  1.0423906295420917\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3010096.110252478\n",
      "Sharpe:  1.0423906295420917\n",
      "=================================\n",
      "Shape of Trade DataFrame:  (7279, 18)\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1013288.8466557632\n",
      "Sharpe:  0.16297298014354425\n",
      "=================================\n",
      "hit end!\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/DRLTrading/results/df_daily_return.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1628/2707277639.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[0mdf_daily_return\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m \u001b[0mdf_daily_return\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/DRLTrading/results/df_daily_return.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[0mdf_actions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3464\u001b[0m         )\n\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3466\u001b[1;33m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[0;32m   3467\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3468\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1103\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         )\n\u001b[1;32m-> 1105\u001b[1;33m         \u001b[0mcsv_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    235\u001b[0m         \"\"\"\n\u001b[0;32m    236\u001b[0m         \u001b[1;31m# apply compression and byte/text conversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m         with get_handle(\n\u001b[0m\u001b[0;32m    238\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/DRLTrading/results/df_daily_return.csv'"
     ]
    }
   ],
   "source": [
    "# 5. Implement DRL Algorithms\n",
    "\n",
    "# initialize\n",
    "agent = DRLAgent(env=env_train)\n",
    "\n",
    "# Model 1: A2C\n",
    "agent = DRLAgent(env=env_train)\n",
    "A2C_PARAMS = {\"n_steps\": 5, \"ent_coef\": 0.005, \"learning_rate\": 0.0002}\n",
    "model_a2c = agent.get_model(model_name=\"a2c\", model_kwargs=A2C_PARAMS)\n",
    "trained_a2c = agent.train_model(\n",
    "    model=model_a2c, tb_log_name=\"a2c\", total_timesteps=50000\n",
    ")\n",
    "trained_a2c.save(\"/DRLTrading/trained_models/trained_a2c.zip\")\n",
    "\n",
    "# Model 2: PPO\n",
    "agent = DRLAgent(env=env_train)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.005,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo = agent.get_model(\"ppo\", model_kwargs=PPO_PARAMS)\n",
    "trained_ppo = agent.train_model(\n",
    "    model=model_ppo, tb_log_name=\"ppo\", total_timesteps=80000\n",
    ")\n",
    "trained_ppo.save(\"/DRLTrading/trained_models/trained_ppo.zip\")\n",
    "\n",
    "# Model 3: DDPG\n",
    "agent = DRLAgent(env=env_train)\n",
    "DDPG_PARAMS = {\"batch_size\": 128, \"buffer_size\": 50000, \"learning_rate\": 0.001}\n",
    "model_ddpg = agent.get_model(\"ddpg\", model_kwargs=DDPG_PARAMS)\n",
    "trained_ddpg = agent.train_model(\n",
    "    model=model_ddpg, tb_log_name=\"ddpg\", total_timesteps=50000\n",
    ")\n",
    "trained_ddpg.save(\"/DRLTrading/trained_models/trained_ddpg.zip\")\n",
    "\n",
    "# Model 4: SAC\n",
    "agent = DRLAgent(env=env_train)\n",
    "SAC_PARAMS = {\n",
    "    \"batch_size\": 128,\n",
    "    \"buffer_size\": 100000,\n",
    "    \"learning_rate\": 0.0003,\n",
    "    \"learning_starts\": 100,\n",
    "    \"ent_coef\": \"auto_0.1\",\n",
    "}\n",
    "model_sac = agent.get_model(\"sac\", model_kwargs=SAC_PARAMS)\n",
    "trained_sac = agent.train_model(\n",
    "    model=model_sac, tb_log_name=\"sac\", total_timesteps=50000\n",
    ")\n",
    "trained_sac.save(\"/DRLTrading/trained_models/trained_sac.zip\")\n",
    "\n",
    "# Model 5: TD3\n",
    "agent = DRLAgent(env=env_train)\n",
    "TD3_PARAMS = {\"batch_size\": 100, \"buffer_size\": 1000000, \"learning_rate\": 0.001}\n",
    "model_td3 = agent.get_model(\"td3\", model_kwargs=TD3_PARAMS)\n",
    "trained_td3 = agent.train_model(\n",
    "    model=model_td3, tb_log_name=\"td3\", total_timesteps=30000\n",
    ")\n",
    "trained_td3.save(\"/DRLTrading/trained_models/trained_td3.zip\")\n",
    "\n",
    "# Trading\n",
    "trade = dp.data_split(df, \"2018-01-01\", \"2019-01-01\")\n",
    "e_trade_gym = StockPortfolioEnv(df=trade, **env_kwargs)\n",
    "\n",
    "print(\"Shape of Trade DataFrame: \", trade.shape)\n",
    "\n",
    "df_daily_return, df_actions = DRLAgent.DRL_prediction(\n",
    "    model=trained_a2c, environment=e_trade_gym\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date  daily_return\n",
      "0  2018-01-02      0.000000\n",
      "1  2018-01-03      0.001633\n",
      "2  2018-01-04      0.003204\n",
      "3  2018-01-05      0.008419\n",
      "4  2018-01-08      0.000566\n",
      "                AAPL      AMGN       AXP        BA       CAT       CRM  \\\n",
      "date                                                                     \n",
      "2018-01-02  0.034483  0.034483  0.034483  0.034483  0.034483  0.034483   \n",
      "2018-01-03  0.062133  0.024628  0.024628  0.046709  0.030228  0.042598   \n",
      "2018-01-04  0.022867  0.022867  0.028693  0.040923  0.022969  0.045719   \n",
      "2018-01-05  0.026071  0.068291  0.037813  0.070867  0.047386  0.026071   \n",
      "2018-01-08  0.019938  0.047013  0.054197  0.019938  0.054197  0.052469   \n",
      "\n",
      "                CSCO       CVX       DIS        GS  ...       MRK      MSFT  \\\n",
      "date                                                ...                       \n",
      "2018-01-02  0.034483  0.034483  0.034483  0.034483  ...  0.034483  0.034483   \n",
      "2018-01-03  0.036491  0.024628  0.024628  0.024628  ...  0.024628  0.024628   \n",
      "2018-01-04  0.022867  0.023630  0.022867  0.022867  ...  0.029475  0.022867   \n",
      "2018-01-05  0.026071  0.026071  0.026071  0.027868  ...  0.062311  0.026071   \n",
      "2018-01-08  0.054197  0.043217  0.032678  0.024766  ...  0.019938  0.044250   \n",
      "\n",
      "                 NKE        PG       TRV       UNH         V        VZ  \\\n",
      "date                                                                     \n",
      "2018-01-02  0.034483  0.034483  0.034483  0.034483  0.034483  0.034483   \n",
      "2018-01-03  0.024628  0.024628  0.027380  0.066947  0.037714  0.045748   \n",
      "2018-01-04  0.062158  0.053301  0.062158  0.027407  0.022867  0.022974   \n",
      "2018-01-05  0.026071  0.026071  0.026071  0.026071  0.026071  0.055134   \n",
      "2018-01-08  0.019938  0.019938  0.054197  0.054197  0.019938  0.022063   \n",
      "\n",
      "                 WBA       WMT  \n",
      "date                            \n",
      "2018-01-02  0.034483  0.034483  \n",
      "2018-01-03  0.025926  0.024628  \n",
      "2018-01-04  0.022867  0.062158  \n",
      "2018-01-05  0.026071  0.033116  \n",
      "2018-01-08  0.026480  0.028910  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_daily_return.head())\n",
    "\n",
    "df_daily_return.to_csv(\"results/df_daily_return.csv\")\n",
    "\n",
    "print(df_actions.head())\n",
    "\n",
    "df_actions.to_csv(\"results/df_actions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============DRL Strategy Stats===========\n",
      "Annual return          0.013342\n",
      "Cumulative returns     0.013289\n",
      "Annual volatility      0.172306\n",
      "Sharpe ratio           0.162973\n",
      "Calmar ratio           0.089409\n",
      "Stability              0.317127\n",
      "Max drawdown          -0.149226\n",
      "Omega ratio            1.029815\n",
      "Sortino ratio          0.220579\n",
      "Skew                  -0.355624\n",
      "Kurtosis               3.369572\n",
      "Tail ratio             0.736978\n",
      "Daily value at risk   -0.021597\n",
      "Alpha                  0.000000\n",
      "Beta                   1.000000\n",
      "dtype: float64\n",
      "==============Get Baseline Stats===========\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (250, 8)\n",
      "Annual return         -0.071511\n",
      "Cumulative returns    -0.070964\n",
      "Annual volatility      0.179326\n",
      "Sharpe ratio          -0.325705\n",
      "Calmar ratio          -0.380947\n",
      "Stability              0.001178\n",
      "Max drawdown          -0.187719\n",
      "Omega ratio            0.943841\n",
      "Sortino ratio         -0.427754\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             0.742993\n",
      "Daily value at risk   -0.022825\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 6. Backtest Our Strategy\n",
    "\n",
    "# 6.1. BackTestStats\n",
    "from pyfolio import timeseries\n",
    "\n",
    "DRL_strat = convert_daily_return_to_pyfolio_ts(df_daily_return)\n",
    "perf_func = timeseries.perf_stats\n",
    "perf_stats_all = perf_func(\n",
    "    returns=DRL_strat,\n",
    "    factor_returns=DRL_strat,\n",
    "    positions=None,\n",
    "    transactions=None,\n",
    "    turnover_denom=\"AGB\",\n",
    ")\n",
    "\n",
    "print(\"==============DRL Strategy Stats===========\")\n",
    "print(perf_stats_all)\n",
    "\n",
    "# baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_df = get_baseline(\n",
    "    ticker=\"^DJI\",\n",
    "    start=df_daily_return.loc[0, \"date\"],\n",
    "    end=df_daily_return.loc[len(df_daily_return) - 1, \"date\"],\n",
    ")\n",
    "\n",
    "stats = backtest_stats(baseline_df, value_col_name=\"close\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (965, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\"><th>Start date</th><td colspan=2>2018-01-02</td></tr>\n",
       "    <tr style=\"text-align: right;\"><th>End date</th><td colspan=2>2018-12-31</td></tr>\n",
       "    <tr style=\"text-align: right;\"><th>Total months</th><td colspan=2>11</td></tr>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Backtest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Annual return</th>\n",
       "      <td>1.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cumulative returns</th>\n",
       "      <td>1.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annual volatility</th>\n",
       "      <td>17.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe ratio</th>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calmar ratio</th>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stability</th>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max drawdown</th>\n",
       "      <td>-14.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Omega ratio</th>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sortino ratio</th>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skew</th>\n",
       "      <td>-0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kurtosis</th>\n",
       "      <td>3.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tail ratio</th>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daily value at risk</th>\n",
       "      <td>-2.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alpha</th>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beta</th>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.int64' object has no attribute 'to_pydatetime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1628/2484038676.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mpyfolio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplotting\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplotting_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfont_scale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     pyfolio.create_full_tear_sheet(\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mreturns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDRL_strat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbenchmark_rets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbaseline_returns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     )\n",
      "\u001b[1;32mC:\\python310\\lib\\site-packages\\pyfolio\\tears.py\u001b[0m in \u001b[0;36mcreate_full_tear_sheet\u001b[1;34m(returns, positions, transactions, market_data, benchmark_rets, slippage, live_start_date, sector_mappings, bayesian, round_trips, estimate_intraday, hide_positions, cone_std, bootstrap, unadjusted_returns, style_factor_panel, sectors, caps, shares_held, volumes, percentile, turnover_denom, set_context, factor_returns, factor_loadings, pos_in_dollars, header_rows, factor_partitions)\u001b[0m\n\u001b[0;32m    199\u001b[0m                                    \u001b[0mset_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mset_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m                                    \u001b[0msector_mappings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msector_mappings\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m                                    estimate_intraday=False)\n\u001b[0m\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtransactions\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python310\\lib\\site-packages\\pyfolio\\plotting.py\u001b[0m in \u001b[0;36mcall_w_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     52\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcall_w_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python310\\lib\\site-packages\\pyfolio\\tears.py\u001b[0m in \u001b[0;36mcreate_returns_tear_sheet\u001b[1;34m(returns, positions, transactions, live_start_date, cone_std, benchmark_rets, bootstrap, turnover_denom, header_rows, return_fig)\u001b[0m\n\u001b[0;32m    502\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbenchmark_rets\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m         \u001b[0max_rolling_beta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msharex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0max_rolling_returns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m         \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    505\u001b[0m     \u001b[0max_rolling_volatility\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msharex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0max_rolling_returns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python310\\lib\\site-packages\\pyfolio\\plotting.py\u001b[0m in \u001b[0;36mshow_worst_drawdown_periods\u001b[1;34m(returns, top)\u001b[0m\n\u001b[0;32m   1662\u001b[0m     \u001b[0mParameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1663\u001b[0m     \u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1664\u001b[1;33m     \u001b[0mreturns\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1665\u001b[0m         \u001b[0mDaily\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoncumulative\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1666\u001b[0m          \u001b[1;33m-\u001b[0m \u001b[0mSee\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mexplanation\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtears\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_full_tear_sheet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python310\\lib\\site-packages\\pyfolio\\timeseries.py\u001b[0m in \u001b[0;36mgen_drawdown_table\u001b[1;34m(returns, top)\u001b[0m\n\u001b[0;32m   1006\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpeak\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalley\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecovery\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrawdown_periods\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1007\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecovery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1008\u001b[1;33m             \u001b[0mdf_drawdowns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Duration'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1009\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1010\u001b[0m             df_drawdowns.loc[i, 'Duration'] = len(pd.date_range(peak,\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.int64' object has no attribute 'to_pydatetime'"
     ]
    }
   ],
   "source": [
    "# 6.2. BackTestPlot\n",
    "import pyfolio\n",
    "\n",
    "baseline_df = get_baseline(\n",
    "    ticker=\"^DJI\", start=df_daily_return.loc[0, \"date\"], end=\"2021-11-01\"\n",
    ")\n",
    "\n",
    "baseline_returns = get_daily_return(baseline_df, value_col_name=\"close\")\n",
    "\n",
    "# with pyfolio.plotting.plotting_context(font_scale=1.1):\n",
    "#     pyfolio.create_full_tear_sheet(\n",
    "#         returns=DRL_strat, benchmark_rets=baseline_returns, set_context=False\n",
    "#     )\n",
    "\n",
    "# Min-Variance Portfolio Allocation\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import risk_models\n",
    "\n",
    "unique_tic = trade.tic.unique()\n",
    "unique_trade_date = trade.date.unique()\n",
    "\n",
    "df.head()\n",
    "\n",
    "# Calculate_portfolio_minimum_variance\n",
    "portfolio = pd.DataFrame(index=range(1), columns=unique_trade_date)\n",
    "initial_capital = 1000000\n",
    "portfolio.loc[0, unique_trade_date[0]] = initial_capital\n",
    "\n",
    "for i in range(len(unique_trade_date) - 1):\n",
    "    df_temp = df[df.date == unique_trade_date[i]].reset_index(drop=True)\n",
    "    df_temp_next = df[df.date == unique_trade_date[i + 1]].reset_index(drop=True)\n",
    "    # Sigma = risk_models.sample_cov(df_temp.return_list[0])\n",
    "\n",
    "    # calculate covariance matrix\n",
    "    Sigma = df_temp.return_list[0].cov()\n",
    "\n",
    "    # portfolio allocation\n",
    "    ef_min_var = EfficientFrontier(None, Sigma, weight_bounds=(0, 0.1))\n",
    "\n",
    "    # minimum variance\n",
    "    raw_weights_min_var = ef_min_var.min_volatility()\n",
    "\n",
    "    # get weights\n",
    "    cleaned_weights_min_var = ef_min_var.clean_weights()\n",
    "\n",
    "    # current capital\n",
    "    cap = portfolio.iloc[0, i]\n",
    "\n",
    "    # current cash invested for each stock\n",
    "    current_cash = [element * cap for element in list(cleaned_weights_min_var.values())]\n",
    "\n",
    "    # current held shares\n",
    "    current_shares = list(np.array(current_cash) / np.array(df_temp.close))\n",
    "\n",
    "    # next time period price\n",
    "    next_price = np.array(df_temp_next.close)\n",
    "\n",
    "    ##next_price * current share to calculate next total account value\n",
    "    portfolio.iloc[0, i + 1] = np.dot(current_shares, next_price)\n",
    "\n",
    "portfolio = portfolio.T\n",
    "portfolio.columns = [\"account_value\"]\n",
    "\n",
    "portfolio.head()\n",
    "\n",
    "a2c_cumpod = (df_daily_return.daily_return + 1).cumprod() - 1\n",
    "\n",
    "min_var_cumpod = (portfolio.account_value.pct_change() + 1).cumprod() - 1\n",
    "\n",
    "dji_cumpod = (baseline_returns + 1).cumprod() - 1\n",
    "\n",
    "# Plotly: DRL, Min-Variance, DJIA\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "time_ind = pd.Series(df_daily_return.date)\n",
    "\n",
    "trace0_portfolio = go.Scatter(\n",
    "    x=time_ind, y=a2c_cumpod, mode=\"lines\", name=\"A2C (Portfolio Allocation)\"\n",
    ")\n",
    "\n",
    "trace1_portfolio = go.Scatter(x=time_ind, y=dji_cumpod, mode=\"lines\", name=\"DJIA\")\n",
    "trace2_portfolio = go.Scatter(\n",
    "    x=time_ind, y=min_var_cumpod, mode=\"lines\", name=\"Min-Variance\"\n",
    ")\n",
    "# trace3_portfolio = go.Scatter(x = time_ind, y = ddpg_cumpod, mode = 'lines', name = 'DDPG')\n",
    "# trace4_portfolio = go.Scatter(x = time_ind, y = addpg_cumpod, mode = 'lines', name = 'Adaptive-DDPG')\n",
    "# trace5_portfolio = go.Scatter(x = time_ind, y = min_cumpod, mode = 'lines', name = 'Min-Variance')\n",
    "# trace4 = go.Scatter(x = time_ind, y = addpg_cumpod, mode = 'lines', name = 'Adaptive-DDPG')\n",
    "# trace2 = go.Scatter(x = time_ind, y = portfolio_cost_minv, mode = 'lines', name = 'Min-Variance')\n",
    "# trace3 = go.Scatter(x = time_ind, y = spx_value, mode = 'lines', name = 'SPX')\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(trace0_portfolio)\n",
    "fig.add_trace(trace1_portfolio)\n",
    "fig.add_trace(trace2_portfolio)\n",
    "\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        x=0,\n",
    "        y=1,\n",
    "        traceorder=\"normal\",\n",
    "        font=dict(family=\"sans-serif\", size=15, color=\"black\"),\n",
    "        bgcolor=\"White\",\n",
    "        bordercolor=\"white\",\n",
    "        borderwidth=2,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# fig.update_layout(legend_orientation=\"h\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        #'text': \"Cumulative Return using FinRL\",\n",
    "        \"y\": 0.85,\n",
    "        \"x\": 0.5,\n",
    "        \"xanchor\": \"center\",\n",
    "        \"yanchor\": \"top\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# with Transaction cost\n",
    "# fig.update_layout(title =  'Quarterly Trade Date')\n",
    "\n",
    "fig.update_layout(\n",
    "    #    margin=dict(l=20, r=20, t=20, b=20),\n",
    "    paper_bgcolor=\"rgba(1,1,0,0)\",\n",
    "    plot_bgcolor=\"rgba(1, 1, 0, 0)\",\n",
    "    # xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Cumulative Return\",\n",
    "    xaxis={\n",
    "        \"type\": \"date\",\n",
    "        \"tick0\": time_ind[0],\n",
    "        \"tickmode\": \"linear\",\n",
    "        \"dtick\": 86400000.0 * 80,\n",
    "    },\n",
    ")\n",
    "fig.update_xaxes(\n",
    "    showline=True,\n",
    "    linecolor=\"black\",\n",
    "    showgrid=True,\n",
    "    gridwidth=1,\n",
    "    gridcolor=\"LightSteelBlue\",\n",
    "    mirror=True,\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    showline=True,\n",
    "    linecolor=\"black\",\n",
    "    showgrid=True,\n",
    "    gridwidth=1,\n",
    "    gridcolor=\"LightSteelBlue\",\n",
    "    mirror=True,\n",
    ")\n",
    "fig.update_yaxes(zeroline=True, zerolinewidth=1, zerolinecolor=\"LightSteelBlue\")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "7417fcd27c28a163675abd79abfa37f0fb8db54e512f8dd446ceb545439c3f53"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
