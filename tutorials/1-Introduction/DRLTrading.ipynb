{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Getting Started - Load Python Packages\n",
    "# 1.1. Import Packages\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.use(\"Agg\")\n",
    "import sys\n",
    "\n",
    "#os.chdir(\"../../../DRLTrading\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pyfolio as pf\n",
    "\n",
    "from meta import config\n",
    "from meta import config_tickers\n",
    "from meta.data_processor import DataProcessor\n",
    "sys.path.append(\"C:\\python310\\lib\\site-packages\")\n",
    "from meta.env_portfolio_allocation.env_portfolio_yahoofinance import (\n",
    "    StockPortfolioEnv,\n",
    ")\n",
    "from agents.stablebaselines3_models import DRLAgent\n",
    "from plot import (\n",
    "    backtest_stats,\n",
    "    backtest_plot,\n",
    "    get_daily_return,\n",
    "    get_baseline,\n",
    "    convert_daily_return_to_pyfolio_ts,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2. Create Folders\n",
    "import main\n",
    "\n",
    "main.check_and_make_directories(\n",
    "    [\n",
    "        config.DATA_SAVE_DIR,\n",
    "        config.TRAINED_MODEL_DIR,\n",
    "        config.TENSORBOARD_LOG_DIR,\n",
    "        config.RESULTS_DIR,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOW_30_TICKER: ['AXP', 'AMGN', 'AAPL', 'BA', 'CAT', 'CSCO', 'CVX', 'GS', 'HD', 'HON', 'IBM', 'INTC', 'JNJ', 'KO', 'JPM', 'MCD', 'MMM', 'MRK', 'MSFT', 'NKE', 'PG', 'TRV', 'UNH', 'CRM', 'VZ', 'V', 'WBA', 'WMT', 'DIS', 'DOW']\n",
      "yahoofinance successfully connected\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "- DOW: Data doesn't exist for startDate = 1230786000, endDate = 1546318800\n",
      "Shape of DataFrame:  (72964, 9)\n",
      "Clean data for AAPL\n",
      "Data clean for AAPL is finished.\n",
      "Clean data for AMGN\n",
      "Data clean for AMGN is finished.\n",
      "Clean data for AXP\n",
      "Data clean for AXP is finished.\n",
      "Clean data for BA\n",
      "Data clean for BA is finished.\n",
      "Clean data for CAT\n",
      "Data clean for CAT is finished.\n",
      "Clean data for CRM\n",
      "Data clean for CRM is finished.\n",
      "Clean data for CSCO\n",
      "Data clean for CSCO is finished.\n",
      "Clean data for CVX\n",
      "Data clean for CVX is finished.\n",
      "Clean data for DIS\n",
      "Data clean for DIS is finished.\n",
      "Clean data for GS\n",
      "Data clean for GS is finished.\n",
      "Clean data for HD\n",
      "Data clean for HD is finished.\n",
      "Clean data for HON\n",
      "Data clean for HON is finished.\n",
      "Clean data for IBM\n",
      "Data clean for IBM is finished.\n",
      "Clean data for INTC\n",
      "Data clean for INTC is finished.\n",
      "Clean data for JNJ\n",
      "Data clean for JNJ is finished.\n",
      "Clean data for JPM\n",
      "Data clean for JPM is finished.\n",
      "Clean data for KO\n",
      "Data clean for KO is finished.\n",
      "Clean data for MCD\n",
      "Data clean for MCD is finished.\n",
      "Clean data for MMM\n",
      "Data clean for MMM is finished.\n",
      "Clean data for MRK\n",
      "Data clean for MRK is finished.\n",
      "Clean data for MSFT\n",
      "Data clean for MSFT is finished.\n",
      "Clean data for NKE\n",
      "Data clean for NKE is finished.\n",
      "Clean data for PG\n",
      "Data clean for PG is finished.\n",
      "Clean data for TRV\n",
      "Data clean for TRV is finished.\n",
      "Clean data for UNH\n",
      "Data clean for UNH is finished.\n",
      "Clean data for V\n",
      "Data clean for V is finished.\n",
      "Clean data for VZ\n",
      "Data clean for VZ is finished.\n",
      "Clean data for WBA\n",
      "Data clean for WBA is finished.\n",
      "Clean data for WMT\n",
      "Data clean for WMT is finished.\n",
      "Data clean all finished!\n",
      "tech_indicator_list:  ['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma']\n",
      "indicator:  macd\n",
      "indicator:  boll_ub\n",
      "indicator:  boll_lb\n",
      "indicator:  rsi_30\n",
      "indicator:  cci_30\n",
      "indicator:  dx_30\n",
      "indicator:  close_30_sma\n",
      "indicator:  close_60_sma\n",
      "Succesfully add technical indicators\n",
      "Successfully transformed into array\n",
      "Shape of DataFrame:  (72906, 17)\n",
      "Shape of DataFrame:  (65598, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjusted_close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>cov_list</th>\n",
       "      <th>return_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>7.656429</td>\n",
       "      <td>7.686786</td>\n",
       "      <td>7.526786</td>\n",
       "      <td>7.534643</td>\n",
       "      <td>6.422665</td>\n",
       "      <td>552160000.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.151770</td>\n",
       "      <td>7.809801</td>\n",
       "      <td>6.634520</td>\n",
       "      <td>59.459729</td>\n",
       "      <td>119.669328</td>\n",
       "      <td>25.355894</td>\n",
       "      <td>7.180202</td>\n",
       "      <td>7.115042</td>\n",
       "      <td>[[0.00043702812754458194, 0.000134165767139395...</td>\n",
       "      <td>tic             AAPL      AMGN       AXP      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>56.939999</td>\n",
       "      <td>57.389999</td>\n",
       "      <td>56.500000</td>\n",
       "      <td>56.790001</td>\n",
       "      <td>42.570049</td>\n",
       "      <td>6015100.0</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>0.271541</td>\n",
       "      <td>58.391582</td>\n",
       "      <td>54.840419</td>\n",
       "      <td>50.007936</td>\n",
       "      <td>27.581378</td>\n",
       "      <td>1.908627</td>\n",
       "      <td>56.658667</td>\n",
       "      <td>56.394500</td>\n",
       "      <td>[[0.00043702812754458194, 0.000134165767139395...</td>\n",
       "      <td>tic             AAPL      AMGN       AXP      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>41.230000</td>\n",
       "      <td>41.669998</td>\n",
       "      <td>41.169998</td>\n",
       "      <td>41.490002</td>\n",
       "      <td>34.263405</td>\n",
       "      <td>8399400.0</td>\n",
       "      <td>AXP</td>\n",
       "      <td>0.354226</td>\n",
       "      <td>41.997035</td>\n",
       "      <td>39.628965</td>\n",
       "      <td>58.194409</td>\n",
       "      <td>79.143497</td>\n",
       "      <td>20.617391</td>\n",
       "      <td>40.788000</td>\n",
       "      <td>39.015000</td>\n",
       "      <td>[[0.00043702812754458194, 0.000134165767139395...</td>\n",
       "      <td>tic             AAPL      AMGN       AXP      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>58.230000</td>\n",
       "      <td>59.990002</td>\n",
       "      <td>57.880001</td>\n",
       "      <td>59.779999</td>\n",
       "      <td>46.582798</td>\n",
       "      <td>8836500.0</td>\n",
       "      <td>BA</td>\n",
       "      <td>1.101808</td>\n",
       "      <td>58.219951</td>\n",
       "      <td>52.756048</td>\n",
       "      <td>65.109172</td>\n",
       "      <td>257.267429</td>\n",
       "      <td>40.596881</td>\n",
       "      <td>54.797333</td>\n",
       "      <td>52.651667</td>\n",
       "      <td>[[0.00043702812754458194, 0.000134165767139395...</td>\n",
       "      <td>tic             AAPL      AMGN       AXP      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>59.180000</td>\n",
       "      <td>59.930000</td>\n",
       "      <td>59.049999</td>\n",
       "      <td>59.430000</td>\n",
       "      <td>41.974724</td>\n",
       "      <td>4718800.0</td>\n",
       "      <td>CAT</td>\n",
       "      <td>0.283309</td>\n",
       "      <td>59.574505</td>\n",
       "      <td>56.181494</td>\n",
       "      <td>56.931953</td>\n",
       "      <td>152.077629</td>\n",
       "      <td>16.584805</td>\n",
       "      <td>58.042000</td>\n",
       "      <td>57.683000</td>\n",
       "      <td>[[0.00043702812754458194, 0.000134165767139395...</td>\n",
       "      <td>tic             AAPL      AMGN       AXP      ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       open       high        low      close  adjusted_close  \\\n",
       "0  2010-01-06   7.656429   7.686786   7.526786   7.534643        6.422665   \n",
       "1  2010-01-06  56.939999  57.389999  56.500000  56.790001       42.570049   \n",
       "2  2010-01-06  41.230000  41.669998  41.169998  41.490002       34.263405   \n",
       "3  2010-01-06  58.230000  59.990002  57.880001  59.779999       46.582798   \n",
       "4  2010-01-06  59.180000  59.930000  59.049999  59.430000       41.974724   \n",
       "\n",
       "        volume   tic      macd    boll_ub    boll_lb     rsi_30      cci_30  \\\n",
       "0  552160000.0  AAPL  0.151770   7.809801   6.634520  59.459729  119.669328   \n",
       "1    6015100.0  AMGN  0.271541  58.391582  54.840419  50.007936   27.581378   \n",
       "2    8399400.0   AXP  0.354226  41.997035  39.628965  58.194409   79.143497   \n",
       "3    8836500.0    BA  1.101808  58.219951  52.756048  65.109172  257.267429   \n",
       "4    4718800.0   CAT  0.283309  59.574505  56.181494  56.931953  152.077629   \n",
       "\n",
       "       dx_30  close_30_sma  close_60_sma  \\\n",
       "0  25.355894      7.180202      7.115042   \n",
       "1   1.908627     56.658667     56.394500   \n",
       "2  20.617391     40.788000     39.015000   \n",
       "3  40.596881     54.797333     52.651667   \n",
       "4  16.584805     58.042000     57.683000   \n",
       "\n",
       "                                            cov_list  \\\n",
       "0  [[0.00043702812754458194, 0.000134165767139395...   \n",
       "1  [[0.00043702812754458194, 0.000134165767139395...   \n",
       "2  [[0.00043702812754458194, 0.000134165767139395...   \n",
       "3  [[0.00043702812754458194, 0.000134165767139395...   \n",
       "4  [[0.00043702812754458194, 0.000134165767139395...   \n",
       "\n",
       "                                         return_list  \n",
       "0  tic             AAPL      AMGN       AXP      ...  \n",
       "1  tic             AAPL      AMGN       AXP      ...  \n",
       "2  tic             AAPL      AMGN       AXP      ...  \n",
       "3  tic             AAPL      AMGN       AXP      ...  \n",
       "4  tic             AAPL      AMGN       AXP      ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Download and Preprocess Data\n",
    "print(f\"DOW_30_TICKER: {config_tickers.DOW_30_TICKER}\")\n",
    "\n",
    "dp = DataProcessor(\n",
    "    data_source=\"yahoofinance\",\n",
    "    start_date=\"2009-01-01\",\n",
    "    end_date=\"2019-01-01\",\n",
    "    time_interval=\"1D\",\n",
    ")\n",
    "\n",
    "dp.run(\n",
    "    ticker_list=config_tickers.DOW_30_TICKER,\n",
    "    technical_indicator_list=config.INDICATORS,\n",
    "    if_vix=False,\n",
    ")\n",
    "df = dp.dataframe\n",
    "\n",
    "df.head()\n",
    "\n",
    "print(\"Shape of DataFrame: \", df.shape)\n",
    "\n",
    "# Add covariance matrix as states\n",
    "df.rename(columns={\"time\": \"date\"}, inplace=True)\n",
    "df = df.sort_values([\"date\", \"tic\"], ignore_index=True)\n",
    "df.index = df.date.factorize()[0]\n",
    "df.drop(columns=[\"index\"], inplace=True)\n",
    "\n",
    "cov_list = []\n",
    "return_list = []\n",
    "\n",
    "# look back is one year\n",
    "lookback = 252\n",
    "for i in range(lookback, len(df.index.unique())):\n",
    "    data_lookback = df.loc[i - lookback : i, :]\n",
    "    price_lookback = data_lookback.pivot_table(\n",
    "        index=\"date\", columns=\"tic\", values=\"close\"\n",
    "    ).dropna(axis=1)\n",
    "    return_lookback = price_lookback.pct_change().dropna()\n",
    "    return_list.append(return_lookback)\n",
    "\n",
    "    covs = return_lookback.cov().values\n",
    "    cov_list.append(covs)\n",
    "\n",
    "df_cov = pd.DataFrame(\n",
    "    {\n",
    "        \"date\": df.date.unique()[lookback:],\n",
    "        \"cov_list\": cov_list,\n",
    "        \"return_list\": return_list,\n",
    "    }\n",
    ")\n",
    "df = df.merge(df_cov, on=\"date\")\n",
    "df = df.sort_values([\"date\", \"tic\"]).reset_index(drop=True)\n",
    "print(\"Shape of DataFrame: \", df.shape)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 29, State Space: 29\n"
     ]
    }
   ],
   "source": [
    "# 4. Design Environment\n",
    "\n",
    "# Training data split: 2009-01-01 to 2018-01-01\n",
    "train = dp.data_split(df, \"2009-01-01\", \"2018-01-01\")\n",
    "\n",
    "train.head()\n",
    "\n",
    "# Environment for Portfolio Allocation\n",
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n",
    "\n",
    "env_kwargs = {\n",
    "    \"hmax\": 100,\n",
    "    \"initial_amount\": 1000000,\n",
    "    \"transaction_cost_pct\": 0.001,\n",
    "    \"state_space\": state_space,\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"tech_indicator_list\": config.INDICATORS,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"reward_scaling\": 1e-4,\n",
    "}\n",
    "\n",
    "e_train_gym = StockPortfolioEnv(df=train, **env_kwargs)\n",
    "\n",
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "# print(type(env_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0002}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c\\a2c_1\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 125       |\n",
      "|    iterations         | 100       |\n",
      "|    time_elapsed       | 3         |\n",
      "|    total_timesteps    | 500       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 99        |\n",
      "|    policy_loss        | 1.47e+08  |\n",
      "|    reward             | 1223603.6 |\n",
      "|    std                | 0.997     |\n",
      "|    value_loss         | 1.51e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 172       |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 5         |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | 2.25e+08  |\n",
      "|    reward             | 1870252.4 |\n",
      "|    std                | 0.996     |\n",
      "|    value_loss         | 3.48e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 206       |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 7         |\n",
      "|    total_timesteps    | 1500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41       |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | 2.59e+08  |\n",
      "|    reward             | 2178126.8 |\n",
      "|    std                | 0.996     |\n",
      "|    value_loss         | 5.07e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 228       |\n",
      "|    iterations         | 400       |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 2000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 399       |\n",
      "|    policy_loss        | 3.42e+08  |\n",
      "|    reward             | 3099699.2 |\n",
      "|    std                | 0.995     |\n",
      "|    value_loss         | 1e+14     |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3130734.904952157\n",
      "Sharpe:  1.0888310316671557\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 233       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 10        |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41       |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | 1.53e+08  |\n",
      "|    reward             | 1183529.9 |\n",
      "|    std                | 0.994     |\n",
      "|    value_loss         | 1.53e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 245       |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 12        |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41       |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | 2.21e+08  |\n",
      "|    reward             | 1823252.1 |\n",
      "|    std                | 0.994     |\n",
      "|    value_loss         | 3.54e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 255       |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 13        |\n",
      "|    total_timesteps    | 3500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -41       |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | 2.58e+08  |\n",
      "|    reward             | 2188873.2 |\n",
      "|    std                | 0.993     |\n",
      "|    value_loss         | 5.06e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 263       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 15        |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | 3.32e+08  |\n",
      "|    reward             | 2838927.2 |\n",
      "|    std                | 0.993     |\n",
      "|    value_loss         | 8.32e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2909162.0803940375\n",
      "Sharpe:  1.0245477628705488\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 264       |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 16        |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | 1.39e+08  |\n",
      "|    reward             | 1110313.4 |\n",
      "|    std                | 0.992     |\n",
      "|    value_loss         | 1.4e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 1000      |\n",
      "|    time_elapsed       | 18        |\n",
      "|    total_timesteps    | 5000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 999       |\n",
      "|    policy_loss        | 2.14e+08  |\n",
      "|    reward             | 1798649.2 |\n",
      "|    std                | 0.992     |\n",
      "|    value_loss         | 3.39e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 268       |\n",
      "|    iterations         | 1100      |\n",
      "|    time_elapsed       | 20        |\n",
      "|    total_timesteps    | 5500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 1099      |\n",
      "|    policy_loss        | 2.48e+08  |\n",
      "|    reward             | 2174940.5 |\n",
      "|    std                | 0.992     |\n",
      "|    value_loss         | 5.04e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 271       |\n",
      "|    iterations         | 1200      |\n",
      "|    time_elapsed       | 22        |\n",
      "|    total_timesteps    | 6000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 1199      |\n",
      "|    policy_loss        | 3.73e+08  |\n",
      "|    reward             | 2793065.0 |\n",
      "|    std                | 0.992     |\n",
      "|    value_loss         | 8.23e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2917229.792756352\n",
      "Sharpe:  1.0322403554095723\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 269       |\n",
      "|    iterations         | 1300      |\n",
      "|    time_elapsed       | 24        |\n",
      "|    total_timesteps    | 6500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 1299      |\n",
      "|    policy_loss        | 1.39e+08  |\n",
      "|    reward             | 1151703.6 |\n",
      "|    std                | 0.992     |\n",
      "|    value_loss         | 1.44e+13  |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 271       |\n",
      "|    iterations         | 1400      |\n",
      "|    time_elapsed       | 25        |\n",
      "|    total_timesteps    | 7000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 1399      |\n",
      "|    policy_loss        | 2.08e+08  |\n",
      "|    reward             | 1729930.0 |\n",
      "|    std                | 0.992     |\n",
      "|    value_loss         | 3.19e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 273       |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 27        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | 2.6e+08   |\n",
      "|    reward             | 2209095.0 |\n",
      "|    std                | 0.991     |\n",
      "|    value_loss         | 4.99e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 275       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 28        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | 3.58e+08  |\n",
      "|    reward             | 2837594.8 |\n",
      "|    std                | 0.991     |\n",
      "|    value_loss         | 8.42e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2977548.3332225215\n",
      "Sharpe:  1.0471584891524501\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 275       |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 30        |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | 1.33e+08  |\n",
      "|    reward             | 1146733.8 |\n",
      "|    std                | 0.991     |\n",
      "|    value_loss         | 1.33e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 277       |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 32        |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | 1.95e+08  |\n",
      "|    reward             | 1689011.5 |\n",
      "|    std                | 0.991     |\n",
      "|    value_loss         | 2.98e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 278       |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 34        |\n",
      "|    total_timesteps    | 9500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | 2.66e+08  |\n",
      "|    reward             | 2037456.8 |\n",
      "|    std                | 0.99      |\n",
      "|    value_loss         | 4.32e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 279       |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 35        |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | 3.2e+08   |\n",
      "|    reward             | 2679077.2 |\n",
      "|    std                | 0.99      |\n",
      "|    value_loss         | 7.62e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2896857.9654859877\n",
      "Sharpe:  1.0244380206676376\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 278       |\n",
      "|    iterations         | 2100      |\n",
      "|    time_elapsed       | 37        |\n",
      "|    total_timesteps    | 10500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | 2.38e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 2099      |\n",
      "|    policy_loss        | 1.3e+08   |\n",
      "|    reward             | 1142330.0 |\n",
      "|    std                | 0.99      |\n",
      "|    value_loss         | 1.25e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 279       |\n",
      "|    iterations         | 2200      |\n",
      "|    time_elapsed       | 39        |\n",
      "|    total_timesteps    | 11000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 2199      |\n",
      "|    policy_loss        | 1.84e+08  |\n",
      "|    reward             | 1696319.2 |\n",
      "|    std                | 0.99      |\n",
      "|    value_loss         | 3.21e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 280       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 41        |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | 2.42e+08  |\n",
      "|    reward             | 2111468.0 |\n",
      "|    std                | 0.99      |\n",
      "|    value_loss         | 4.64e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 281       |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 42        |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | 3.45e+08  |\n",
      "|    reward             | 2849540.0 |\n",
      "|    std                | 0.989     |\n",
      "|    value_loss         | 8.72e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3092019.287706469\n",
      "Sharpe:  1.0754239974928164\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 280       |\n",
      "|    iterations         | 2500      |\n",
      "|    time_elapsed       | 44        |\n",
      "|    total_timesteps    | 12500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 2499      |\n",
      "|    policy_loss        | 1.39e+08  |\n",
      "|    reward             | 1079583.1 |\n",
      "|    std                | 0.989     |\n",
      "|    value_loss         | 1.32e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 281       |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 46        |\n",
      "|    total_timesteps    | 13000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | 2.01e+08  |\n",
      "|    reward             | 1688966.4 |\n",
      "|    std                | 0.988     |\n",
      "|    value_loss         | 2.96e+13  |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 282       |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 47        |\n",
      "|    total_timesteps    | 13500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 2699      |\n",
      "|    policy_loss        | 2.54e+08  |\n",
      "|    reward             | 1985489.9 |\n",
      "|    std                | 0.988     |\n",
      "|    value_loss         | 4.03e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 283       |\n",
      "|    iterations         | 2800      |\n",
      "|    time_elapsed       | 49        |\n",
      "|    total_timesteps    | 14000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 2799      |\n",
      "|    policy_loss        | 3.14e+08  |\n",
      "|    reward             | 2632738.5 |\n",
      "|    std                | 0.988     |\n",
      "|    value_loss         | 7.15e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2888783.2124918653\n",
      "Sharpe:  1.0108423557752935\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 283       |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 51        |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | 1.43e+08  |\n",
      "|    reward             | 1072931.1 |\n",
      "|    std                | 0.988     |\n",
      "|    value_loss         | 1.33e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 283       |\n",
      "|    iterations         | 3000      |\n",
      "|    time_elapsed       | 52        |\n",
      "|    total_timesteps    | 15000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 2999      |\n",
      "|    policy_loss        | 1.98e+08  |\n",
      "|    reward             | 1681716.9 |\n",
      "|    std                | 0.988     |\n",
      "|    value_loss         | 2.95e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 284       |\n",
      "|    iterations         | 3100      |\n",
      "|    time_elapsed       | 54        |\n",
      "|    total_timesteps    | 15500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 3099      |\n",
      "|    policy_loss        | 2.35e+08  |\n",
      "|    reward             | 1991850.6 |\n",
      "|    std                | 0.987     |\n",
      "|    value_loss         | 4.32e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 283       |\n",
      "|    iterations         | 3200      |\n",
      "|    time_elapsed       | 56        |\n",
      "|    total_timesteps    | 16000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 3199      |\n",
      "|    policy_loss        | 3.32e+08  |\n",
      "|    reward             | 2682644.5 |\n",
      "|    std                | 0.987     |\n",
      "|    value_loss         | 7.69e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2959722.0292506106\n",
      "Sharpe:  1.0392949437294445\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 281       |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 58        |\n",
      "|    total_timesteps    | 16500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | 1.33e+08  |\n",
      "|    reward             | 1094429.1 |\n",
      "|    std                | 0.987     |\n",
      "|    value_loss         | 1.3e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 281       |\n",
      "|    iterations         | 3400      |\n",
      "|    time_elapsed       | 60        |\n",
      "|    total_timesteps    | 17000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 3399      |\n",
      "|    policy_loss        | 1.98e+08  |\n",
      "|    reward             | 1600533.2 |\n",
      "|    std                | 0.987     |\n",
      "|    value_loss         | 2.9e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 280       |\n",
      "|    iterations         | 3500      |\n",
      "|    time_elapsed       | 62        |\n",
      "|    total_timesteps    | 17500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.8     |\n",
      "|    explained_variance | 3.58e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 3499      |\n",
      "|    policy_loss        | 2.56e+08  |\n",
      "|    reward             | 2178694.8 |\n",
      "|    std                | 0.987     |\n",
      "|    value_loss         | 5e+13     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 281       |\n",
      "|    iterations         | 3600      |\n",
      "|    time_elapsed       | 63        |\n",
      "|    total_timesteps    | 18000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 3599      |\n",
      "|    policy_loss        | 3.29e+08  |\n",
      "|    reward             | 2600979.8 |\n",
      "|    std                | 0.986     |\n",
      "|    value_loss         | 7.29e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2910976.444184313\n",
      "Sharpe:  1.0237237906054377\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 280       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 65        |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | 1.48e+08  |\n",
      "|    reward             | 1110055.2 |\n",
      "|    std                | 0.986     |\n",
      "|    value_loss         | 1.52e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 280       |\n",
      "|    iterations         | 3800      |\n",
      "|    time_elapsed       | 67        |\n",
      "|    total_timesteps    | 19000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 3799      |\n",
      "|    policy_loss        | 2.05e+08  |\n",
      "|    reward             | 1700292.2 |\n",
      "|    std                | 0.985     |\n",
      "|    value_loss         | 3.07e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 281       |\n",
      "|    iterations         | 3900      |\n",
      "|    time_elapsed       | 69        |\n",
      "|    total_timesteps    | 19500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 3899      |\n",
      "|    policy_loss        | 2.69e+08  |\n",
      "|    reward             | 2195072.8 |\n",
      "|    std                | 0.985     |\n",
      "|    value_loss         | 5.09e+13  |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 281       |\n",
      "|    iterations         | 4000      |\n",
      "|    time_elapsed       | 71        |\n",
      "|    total_timesteps    | 20000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 3999      |\n",
      "|    policy_loss        | 3.09e+08  |\n",
      "|    reward             | 2593613.5 |\n",
      "|    std                | 0.985     |\n",
      "|    value_loss         | 7.1e+13   |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2895512.5536924223\n",
      "Sharpe:  1.0187737429565393\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 281       |\n",
      "|    iterations         | 4100      |\n",
      "|    time_elapsed       | 72        |\n",
      "|    total_timesteps    | 20500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 4099      |\n",
      "|    policy_loss        | 1.39e+08  |\n",
      "|    reward             | 1220790.9 |\n",
      "|    std                | 0.985     |\n",
      "|    value_loss         | 1.55e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 281       |\n",
      "|    iterations         | 4200      |\n",
      "|    time_elapsed       | 74        |\n",
      "|    total_timesteps    | 21000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 4199      |\n",
      "|    policy_loss        | 2.03e+08  |\n",
      "|    reward             | 1699239.2 |\n",
      "|    std                | 0.985     |\n",
      "|    value_loss         | 3.02e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 281       |\n",
      "|    iterations         | 4300      |\n",
      "|    time_elapsed       | 76        |\n",
      "|    total_timesteps    | 21500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.7     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 4299      |\n",
      "|    policy_loss        | 2.5e+08   |\n",
      "|    reward             | 2281188.8 |\n",
      "|    std                | 0.984     |\n",
      "|    value_loss         | 5.17e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 281       |\n",
      "|    iterations         | 4400      |\n",
      "|    time_elapsed       | 78        |\n",
      "|    total_timesteps    | 22000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 4399      |\n",
      "|    policy_loss        | 3.5e+08   |\n",
      "|    reward             | 2695918.2 |\n",
      "|    std                | 0.983     |\n",
      "|    value_loss         | 7.76e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3124713.8029378033\n",
      "Sharpe:  1.086655291545142\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 280       |\n",
      "|    iterations         | 4500      |\n",
      "|    time_elapsed       | 80        |\n",
      "|    total_timesteps    | 22500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 4499      |\n",
      "|    policy_loss        | 1.34e+08  |\n",
      "|    reward             | 1239191.8 |\n",
      "|    std                | 0.983     |\n",
      "|    value_loss         | 1.51e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 281       |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 81        |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | 1.96e+08  |\n",
      "|    reward             | 1634989.9 |\n",
      "|    std                | 0.982     |\n",
      "|    value_loss         | 2.75e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 281       |\n",
      "|    iterations         | 4700      |\n",
      "|    time_elapsed       | 83        |\n",
      "|    total_timesteps    | 23500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 4699      |\n",
      "|    policy_loss        | 2.58e+08  |\n",
      "|    reward             | 2122085.0 |\n",
      "|    std                | 0.982     |\n",
      "|    value_loss         | 5.1e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 280       |\n",
      "|    iterations         | 4800      |\n",
      "|    time_elapsed       | 85        |\n",
      "|    total_timesteps    | 24000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 4799      |\n",
      "|    policy_loss        | 2.81e+08  |\n",
      "|    reward             | 2524574.0 |\n",
      "|    std                | 0.981     |\n",
      "|    value_loss         | 6.71e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2870222.6082721814\n",
      "Sharpe:  1.0090993333708664\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 279       |\n",
      "|    iterations         | 4900      |\n",
      "|    time_elapsed       | 87        |\n",
      "|    total_timesteps    | 24500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 4899      |\n",
      "|    policy_loss        | 1.43e+08  |\n",
      "|    reward             | 1168467.1 |\n",
      "|    std                | 0.981     |\n",
      "|    value_loss         | 1.45e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 278       |\n",
      "|    iterations         | 5000      |\n",
      "|    time_elapsed       | 89        |\n",
      "|    total_timesteps    | 25000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 4999      |\n",
      "|    policy_loss        | 1.93e+08  |\n",
      "|    reward             | 1591594.5 |\n",
      "|    std                | 0.981     |\n",
      "|    value_loss         | 2.71e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 278       |\n",
      "|    iterations         | 5100      |\n",
      "|    time_elapsed       | 91        |\n",
      "|    total_timesteps    | 25500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 5099      |\n",
      "|    policy_loss        | 2.38e+08  |\n",
      "|    reward             | 2068016.0 |\n",
      "|    std                | 0.98      |\n",
      "|    value_loss         | 4.61e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 278       |\n",
      "|    iterations         | 5200      |\n",
      "|    time_elapsed       | 93        |\n",
      "|    total_timesteps    | 26000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 5199      |\n",
      "|    policy_loss        | 2.87e+08  |\n",
      "|    reward             | 2500034.8 |\n",
      "|    std                | 0.98      |\n",
      "|    value_loss         | 6.57e+13  |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2855009.5822724234\n",
      "Sharpe:  1.0086634672845867\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 277       |\n",
      "|    iterations         | 5300      |\n",
      "|    time_elapsed       | 95        |\n",
      "|    total_timesteps    | 26500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 5299      |\n",
      "|    policy_loss        | 1.41e+08  |\n",
      "|    reward             | 1184550.5 |\n",
      "|    std                | 0.98      |\n",
      "|    value_loss         | 1.59e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 277       |\n",
      "|    iterations         | 5400      |\n",
      "|    time_elapsed       | 97        |\n",
      "|    total_timesteps    | 27000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.6     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 5399      |\n",
      "|    policy_loss        | 2.14e+08  |\n",
      "|    reward             | 1694961.0 |\n",
      "|    std                | 0.98      |\n",
      "|    value_loss         | 3.16e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 277       |\n",
      "|    iterations         | 5500      |\n",
      "|    time_elapsed       | 99        |\n",
      "|    total_timesteps    | 27500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 5499      |\n",
      "|    policy_loss        | 2.68e+08  |\n",
      "|    reward             | 2231283.2 |\n",
      "|    std                | 0.979     |\n",
      "|    value_loss         | 5.48e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 277       |\n",
      "|    iterations         | 5600      |\n",
      "|    time_elapsed       | 101       |\n",
      "|    total_timesteps    | 28000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 5599      |\n",
      "|    policy_loss        | 3.45e+08  |\n",
      "|    reward             | 2685666.2 |\n",
      "|    std                | 0.979     |\n",
      "|    value_loss         | 7.74e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3080264.4096156103\n",
      "Sharpe:  1.080912788477018\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 276       |\n",
      "|    iterations         | 5700      |\n",
      "|    time_elapsed       | 103       |\n",
      "|    total_timesteps    | 28500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 5699      |\n",
      "|    policy_loss        | 1.57e+08  |\n",
      "|    reward             | 1203872.6 |\n",
      "|    std                | 0.979     |\n",
      "|    value_loss         | 1.58e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 276       |\n",
      "|    iterations         | 5800      |\n",
      "|    time_elapsed       | 104       |\n",
      "|    total_timesteps    | 29000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 5799      |\n",
      "|    policy_loss        | 1.89e+08  |\n",
      "|    reward             | 1614770.5 |\n",
      "|    std                | 0.979     |\n",
      "|    value_loss         | 2.65e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 276       |\n",
      "|    iterations         | 5900      |\n",
      "|    time_elapsed       | 106       |\n",
      "|    total_timesteps    | 29500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 5899      |\n",
      "|    policy_loss        | 2.64e+08  |\n",
      "|    reward             | 2120314.5 |\n",
      "|    std                | 0.979     |\n",
      "|    value_loss         | 4.75e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 275       |\n",
      "|    iterations         | 6000      |\n",
      "|    time_elapsed       | 108       |\n",
      "|    total_timesteps    | 30000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 5999      |\n",
      "|    policy_loss        | 2.94e+08  |\n",
      "|    reward             | 2544554.0 |\n",
      "|    std                | 0.979     |\n",
      "|    value_loss         | 6.87e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2893429.1511162124\n",
      "Sharpe:  1.0280557117311977\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 275       |\n",
      "|    iterations         | 6100      |\n",
      "|    time_elapsed       | 110       |\n",
      "|    total_timesteps    | 30500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 6099      |\n",
      "|    policy_loss        | 1.4e+08   |\n",
      "|    reward             | 1192182.8 |\n",
      "|    std                | 0.979     |\n",
      "|    value_loss         | 1.5e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 274       |\n",
      "|    iterations         | 6200      |\n",
      "|    time_elapsed       | 112       |\n",
      "|    total_timesteps    | 31000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 6199      |\n",
      "|    policy_loss        | 1.85e+08  |\n",
      "|    reward             | 1623005.9 |\n",
      "|    std                | 0.978     |\n",
      "|    value_loss         | 2.76e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 274       |\n",
      "|    iterations         | 6300      |\n",
      "|    time_elapsed       | 114       |\n",
      "|    total_timesteps    | 31500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 6299      |\n",
      "|    policy_loss        | 2.47e+08  |\n",
      "|    reward             | 2217634.0 |\n",
      "|    std                | 0.977     |\n",
      "|    value_loss         | 5.18e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 274       |\n",
      "|    iterations         | 6400      |\n",
      "|    time_elapsed       | 116       |\n",
      "|    total_timesteps    | 32000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 6399      |\n",
      "|    policy_loss        | 3.11e+08  |\n",
      "|    reward             | 2633652.5 |\n",
      "|    std                | 0.977     |\n",
      "|    value_loss         | 7.38e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3084331.020548437\n",
      "Sharpe:  1.0890868718889994\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 273       |\n",
      "|    iterations         | 6500      |\n",
      "|    time_elapsed       | 118       |\n",
      "|    total_timesteps    | 32500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 6499      |\n",
      "|    policy_loss        | 1.36e+08  |\n",
      "|    reward             | 1177273.2 |\n",
      "|    std                | 0.977     |\n",
      "|    value_loss         | 1.49e+13  |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 273       |\n",
      "|    iterations         | 6600      |\n",
      "|    time_elapsed       | 120       |\n",
      "|    total_timesteps    | 33000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | 2.38e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 6599      |\n",
      "|    policy_loss        | 1.91e+08  |\n",
      "|    reward             | 1583927.4 |\n",
      "|    std                | 0.976     |\n",
      "|    value_loss         | 2.69e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 272       |\n",
      "|    iterations         | 6700      |\n",
      "|    time_elapsed       | 122       |\n",
      "|    total_timesteps    | 33500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 6699      |\n",
      "|    policy_loss        | 2.72e+08  |\n",
      "|    reward             | 2151766.2 |\n",
      "|    std                | 0.976     |\n",
      "|    value_loss         | 4.84e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 272       |\n",
      "|    iterations         | 6800      |\n",
      "|    time_elapsed       | 124       |\n",
      "|    total_timesteps    | 34000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 6799      |\n",
      "|    policy_loss        | 2.87e+08  |\n",
      "|    reward             | 2508696.0 |\n",
      "|    std                | 0.975     |\n",
      "|    value_loss         | 6.72e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2995286.4124393486\n",
      "Sharpe:  1.0624412831012378\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 271       |\n",
      "|    iterations         | 6900      |\n",
      "|    time_elapsed       | 126       |\n",
      "|    total_timesteps    | 34500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 6899      |\n",
      "|    policy_loss        | 1.32e+08  |\n",
      "|    reward             | 1168325.9 |\n",
      "|    std                | 0.976     |\n",
      "|    value_loss         | 1.4e+13   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 270       |\n",
      "|    iterations         | 7000      |\n",
      "|    time_elapsed       | 129       |\n",
      "|    total_timesteps    | 35000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 6999      |\n",
      "|    policy_loss        | 1.98e+08  |\n",
      "|    reward             | 1582604.1 |\n",
      "|    std                | 0.975     |\n",
      "|    value_loss         | 2.58e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 270       |\n",
      "|    iterations         | 7100      |\n",
      "|    time_elapsed       | 131       |\n",
      "|    total_timesteps    | 35500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 7099      |\n",
      "|    policy_loss        | 2.33e+08  |\n",
      "|    reward             | 2038362.8 |\n",
      "|    std                | 0.974     |\n",
      "|    value_loss         | 4.56e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 269       |\n",
      "|    iterations         | 7200      |\n",
      "|    time_elapsed       | 133       |\n",
      "|    total_timesteps    | 36000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 7199      |\n",
      "|    policy_loss        | 3.08e+08  |\n",
      "|    reward             | 2457674.0 |\n",
      "|    std                | 0.974     |\n",
      "|    value_loss         | 6.64e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2925185.3625470363\n",
      "Sharpe:  1.0386959447715718\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 268       |\n",
      "|    iterations         | 7300      |\n",
      "|    time_elapsed       | 136       |\n",
      "|    total_timesteps    | 36500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 7299      |\n",
      "|    policy_loss        | 1.5e+08   |\n",
      "|    reward             | 1144095.2 |\n",
      "|    std                | 0.974     |\n",
      "|    value_loss         | 1.48e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 267       |\n",
      "|    iterations         | 7400      |\n",
      "|    time_elapsed       | 138       |\n",
      "|    total_timesteps    | 37000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 7399      |\n",
      "|    policy_loss        | 1.71e+08  |\n",
      "|    reward             | 1539182.9 |\n",
      "|    std                | 0.973     |\n",
      "|    value_loss         | 2.49e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 266       |\n",
      "|    iterations         | 7500      |\n",
      "|    time_elapsed       | 140       |\n",
      "|    total_timesteps    | 37500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 7499      |\n",
      "|    policy_loss        | 2.61e+08  |\n",
      "|    reward             | 2117850.2 |\n",
      "|    std                | 0.972     |\n",
      "|    value_loss         | 5.12e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 264       |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 143       |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | 3.04e+08  |\n",
      "|    reward             | 2580729.5 |\n",
      "|    std                | 0.972     |\n",
      "|    value_loss         | 7.01e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3014579.8563757977\n",
      "Sharpe:  1.0682685965217822\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 264       |\n",
      "|    iterations         | 7700      |\n",
      "|    time_elapsed       | 145       |\n",
      "|    total_timesteps    | 38500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 7699      |\n",
      "|    policy_loss        | 1.34e+08  |\n",
      "|    reward             | 1129933.9 |\n",
      "|    std                | 0.972     |\n",
      "|    value_loss         | 1.33e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 263       |\n",
      "|    iterations         | 7800      |\n",
      "|    time_elapsed       | 147       |\n",
      "|    total_timesteps    | 39000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 7799      |\n",
      "|    policy_loss        | 1.72e+08  |\n",
      "|    reward             | 1403920.5 |\n",
      "|    std                | 0.972     |\n",
      "|    value_loss         | 2.09e+13  |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 263       |\n",
      "|    iterations         | 7900      |\n",
      "|    time_elapsed       | 149       |\n",
      "|    total_timesteps    | 39500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 7899      |\n",
      "|    policy_loss        | 2.38e+08  |\n",
      "|    reward             | 1990260.9 |\n",
      "|    std                | 0.972     |\n",
      "|    value_loss         | 4.11e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 263       |\n",
      "|    iterations         | 8000      |\n",
      "|    time_elapsed       | 151       |\n",
      "|    total_timesteps    | 40000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 7999      |\n",
      "|    policy_loss        | 2.64e+08  |\n",
      "|    reward             | 2271413.2 |\n",
      "|    std                | 0.971     |\n",
      "|    value_loss         | 5.23e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2769455.358378133\n",
      "Sharpe:  0.9900427358059003\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 262       |\n",
      "|    iterations         | 8100      |\n",
      "|    time_elapsed       | 154       |\n",
      "|    total_timesteps    | 40500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 8099      |\n",
      "|    policy_loss        | 1.37e+08  |\n",
      "|    reward             | 1151498.0 |\n",
      "|    std                | 0.971     |\n",
      "|    value_loss         | 1.39e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 262       |\n",
      "|    iterations         | 8200      |\n",
      "|    time_elapsed       | 156       |\n",
      "|    total_timesteps    | 41000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 8199      |\n",
      "|    policy_loss        | 1.7e+08   |\n",
      "|    reward             | 1432276.6 |\n",
      "|    std                | 0.97      |\n",
      "|    value_loss         | 2.15e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 262       |\n",
      "|    iterations         | 8300      |\n",
      "|    time_elapsed       | 158       |\n",
      "|    total_timesteps    | 41500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 8299      |\n",
      "|    policy_loss        | 2.53e+08  |\n",
      "|    reward             | 2022807.9 |\n",
      "|    std                | 0.97      |\n",
      "|    value_loss         | 4.22e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 262       |\n",
      "|    iterations         | 8400      |\n",
      "|    time_elapsed       | 160       |\n",
      "|    total_timesteps    | 42000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 8399      |\n",
      "|    policy_loss        | 3e+08     |\n",
      "|    reward             | 2362549.8 |\n",
      "|    std                | 0.97      |\n",
      "|    value_loss         | 5.94e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2922552.741782834\n",
      "Sharpe:  1.0392665284709757\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 261       |\n",
      "|    iterations         | 8500      |\n",
      "|    time_elapsed       | 162       |\n",
      "|    total_timesteps    | 42500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 8499      |\n",
      "|    policy_loss        | 1.35e+08  |\n",
      "|    reward             | 1119295.8 |\n",
      "|    std                | 0.969     |\n",
      "|    value_loss         | 1.37e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 261       |\n",
      "|    iterations         | 8600      |\n",
      "|    time_elapsed       | 164       |\n",
      "|    total_timesteps    | 43000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 8599      |\n",
      "|    policy_loss        | 1.62e+08  |\n",
      "|    reward             | 1419471.8 |\n",
      "|    std                | 0.968     |\n",
      "|    value_loss         | 2.09e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 261       |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 166       |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | 2.35e+08  |\n",
      "|    reward             | 2033879.2 |\n",
      "|    std                | 0.968     |\n",
      "|    value_loss         | 4.34e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 261       |\n",
      "|    iterations         | 8800      |\n",
      "|    time_elapsed       | 168       |\n",
      "|    total_timesteps    | 44000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 8799      |\n",
      "|    policy_loss        | 2.69e+08  |\n",
      "|    reward             | 2393803.8 |\n",
      "|    std                | 0.967     |\n",
      "|    value_loss         | 6.1e+13   |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2941236.800267004\n",
      "Sharpe:  1.0459326202068846\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 261       |\n",
      "|    iterations         | 8900      |\n",
      "|    time_elapsed       | 170       |\n",
      "|    total_timesteps    | 44500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 8899      |\n",
      "|    policy_loss        | 1.33e+08  |\n",
      "|    reward             | 1188718.9 |\n",
      "|    std                | 0.966     |\n",
      "|    value_loss         | 1.49e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 261       |\n",
      "|    iterations         | 9000      |\n",
      "|    time_elapsed       | 172       |\n",
      "|    total_timesteps    | 45000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.2     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 8999      |\n",
      "|    policy_loss        | 1.74e+08  |\n",
      "|    reward             | 1536585.8 |\n",
      "|    std                | 0.967     |\n",
      "|    value_loss         | 2.43e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 261       |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 174       |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | -3.58e-07 |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | 2.92e+08  |\n",
      "|    reward             | 2257815.0 |\n",
      "|    std                | 0.966     |\n",
      "|    value_loss         | 5.86e+13  |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 260       |\n",
      "|    iterations         | 9200      |\n",
      "|    time_elapsed       | 176       |\n",
      "|    total_timesteps    | 46000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 9199      |\n",
      "|    policy_loss        | 3.35e+08  |\n",
      "|    reward             | 2649218.2 |\n",
      "|    std                | 0.966     |\n",
      "|    value_loss         | 7.57e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3315641.3796936427\n",
      "Sharpe:  1.146304039038519\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 260       |\n",
      "|    iterations         | 9300      |\n",
      "|    time_elapsed       | 178       |\n",
      "|    total_timesteps    | 46500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 9299      |\n",
      "|    policy_loss        | 1.4e+08   |\n",
      "|    reward             | 1121482.0 |\n",
      "|    std                | 0.966     |\n",
      "|    value_loss         | 1.32e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 260       |\n",
      "|    iterations         | 9400      |\n",
      "|    time_elapsed       | 180       |\n",
      "|    total_timesteps    | 47000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 9399      |\n",
      "|    policy_loss        | 1.66e+08  |\n",
      "|    reward             | 1453927.2 |\n",
      "|    std                | 0.966     |\n",
      "|    value_loss         | 2.26e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 260       |\n",
      "|    iterations         | 9500      |\n",
      "|    time_elapsed       | 182       |\n",
      "|    total_timesteps    | 47500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 9499      |\n",
      "|    policy_loss        | 2.58e+08  |\n",
      "|    reward             | 2257446.8 |\n",
      "|    std                | 0.966     |\n",
      "|    value_loss         | 5.35e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 259       |\n",
      "|    iterations         | 9600      |\n",
      "|    time_elapsed       | 184       |\n",
      "|    total_timesteps    | 48000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 9599      |\n",
      "|    policy_loss        | 2.96e+08  |\n",
      "|    reward             | 2585675.5 |\n",
      "|    std                | 0.965     |\n",
      "|    value_loss         | 6.61e+13  |\n",
      "-------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3258428.8148002718\n",
      "Sharpe:  1.1330571983175797\n",
      "=================================\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 258       |\n",
      "|    iterations         | 9700      |\n",
      "|    time_elapsed       | 187       |\n",
      "|    total_timesteps    | 48500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 9699      |\n",
      "|    policy_loss        | 1.25e+08  |\n",
      "|    reward             | 1132508.5 |\n",
      "|    std                | 0.965     |\n",
      "|    value_loss         | 1.34e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 257       |\n",
      "|    iterations         | 9800      |\n",
      "|    time_elapsed       | 190       |\n",
      "|    total_timesteps    | 49000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 9799      |\n",
      "|    policy_loss        | 1.55e+08  |\n",
      "|    reward             | 1388638.8 |\n",
      "|    std                | 0.964     |\n",
      "|    value_loss         | 2.01e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 256       |\n",
      "|    iterations         | 9900      |\n",
      "|    time_elapsed       | 192       |\n",
      "|    total_timesteps    | 49500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 9899      |\n",
      "|    policy_loss        | 2.55e+08  |\n",
      "|    reward             | 2105287.0 |\n",
      "|    std                | 0.964     |\n",
      "|    value_loss         | 4.63e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 255       |\n",
      "|    iterations         | 10000     |\n",
      "|    time_elapsed       | 195       |\n",
      "|    total_timesteps    | 50000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -40.1     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 9999      |\n",
      "|    policy_loss        | 2.57e+08  |\n",
      "|    reward             | 2243313.0 |\n",
      "|    std                | 0.963     |\n",
      "|    value_loss         | 5.26e+13  |\n",
      "-------------------------------------\n",
      "{'n_steps': 2048, 'ent_coef': 0.005, 'learning_rate': 0.0001, 'batch_size': 128}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ppo\\ppo_1\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2967342.693674334\n",
      "Sharpe:  1.0419906346170262\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    fps             | 192       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 10        |\n",
      "|    total_timesteps | 2048      |\n",
      "| train/             |           |\n",
      "|    reward          | 997498.94 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2889907.364438365\n",
      "Sharpe:  1.0138732418896823\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 209       |\n",
      "|    iterations           | 2         |\n",
      "|    time_elapsed         | 19        |\n",
      "|    total_timesteps      | 4096      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.73e+14  |\n",
      "|    n_updates            | 10        |\n",
      "|    policy_gradient_loss | -6.21e-07 |\n",
      "|    reward               | 1062010.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.16e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2853402.9390438143\n",
      "Sharpe:  1.007861623474288\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 217       |\n",
      "|    iterations           | 3         |\n",
      "|    time_elapsed         | 28        |\n",
      "|    total_timesteps      | 6144      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.61e+14  |\n",
      "|    n_updates            | 20        |\n",
      "|    policy_gradient_loss | -6.74e-07 |\n",
      "|    reward               | 986807.75 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.22e+14  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2829840.4270706326\n",
      "Sharpe:  0.9940040267159201\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 224        |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 36         |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0        |\n",
      "|    clip_fraction        | 0          |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.1      |\n",
      "|    explained_variance   | 0          |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 4.36e+14   |\n",
      "|    n_updates            | 30         |\n",
      "|    policy_gradient_loss | -7.89e-07  |\n",
      "|    reward               | 1025102.56 |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 8.84e+14   |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3005626.366239759\n",
      "Sharpe:  1.0525431553548703\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 225        |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 45         |\n",
      "|    total_timesteps      | 10240      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.0        |\n",
      "|    clip_fraction        | 0          |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -41.1      |\n",
      "|    explained_variance   | -2.38e-07  |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 3.98e+14   |\n",
      "|    n_updates            | 40         |\n",
      "|    policy_gradient_loss | -5.41e-07  |\n",
      "|    reward               | 1034296.06 |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 8.34e+14   |\n",
      "----------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2976240.8298893725\n",
      "Sharpe:  1.0445926071927438\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 234       |\n",
      "|    iterations           | 6         |\n",
      "|    time_elapsed         | 52        |\n",
      "|    total_timesteps      | 12288     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 5.31e+14  |\n",
      "|    n_updates            | 50        |\n",
      "|    policy_gradient_loss | -8.1e-07  |\n",
      "|    reward               | 1097278.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.64e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3108773.532913928\n",
      "Sharpe:  1.082333131597568\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 240       |\n",
      "|    iterations           | 7         |\n",
      "|    time_elapsed         | 59        |\n",
      "|    total_timesteps      | 14336     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.53e+14  |\n",
      "|    n_updates            | 60        |\n",
      "|    policy_gradient_loss | -8.02e-07 |\n",
      "|    reward               | 1169091.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.31e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3005234.6810068605\n",
      "Sharpe:  1.050014289787089\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 246       |\n",
      "|    iterations           | 8         |\n",
      "|    time_elapsed         | 66        |\n",
      "|    total_timesteps      | 16384     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.86e+14  |\n",
      "|    n_updates            | 70        |\n",
      "|    policy_gradient_loss | -6.34e-07 |\n",
      "|    reward               | 1154484.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.43e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3110581.271118974\n",
      "Sharpe:  1.0847632198816346\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 251       |\n",
      "|    iterations           | 9         |\n",
      "|    time_elapsed         | 73        |\n",
      "|    total_timesteps      | 18432     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.91e+14  |\n",
      "|    n_updates            | 80        |\n",
      "|    policy_gradient_loss | -8.18e-07 |\n",
      "|    reward               | 1218322.6 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.4e+14   |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2969632.0011570943\n",
      "Sharpe:  1.0460682742018086\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 256       |\n",
      "|    iterations           | 10        |\n",
      "|    time_elapsed         | 79        |\n",
      "|    total_timesteps      | 20480     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.69e+14  |\n",
      "|    n_updates            | 90        |\n",
      "|    policy_gradient_loss | -8.12e-07 |\n",
      "|    reward               | 1135051.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.82e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2849143.689202709\n",
      "Sharpe:  1.0033065569035897\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 260       |\n",
      "|    iterations           | 11        |\n",
      "|    time_elapsed         | 86        |\n",
      "|    total_timesteps      | 22528     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.39e+14  |\n",
      "|    n_updates            | 100       |\n",
      "|    policy_gradient_loss | -6.79e-07 |\n",
      "|    reward               | 1106039.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.07e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2977914.7616431057\n",
      "Sharpe:  1.0516097090989152\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 264       |\n",
      "|    iterations           | 12        |\n",
      "|    time_elapsed         | 93        |\n",
      "|    total_timesteps      | 24576     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.52e+14  |\n",
      "|    n_updates            | 110       |\n",
      "|    policy_gradient_loss | -7.95e-07 |\n",
      "|    reward               | 1094774.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.82e+14  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3014469.643773869\n",
      "Sharpe:  1.0533350952962848\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 267       |\n",
      "|    iterations           | 13        |\n",
      "|    time_elapsed         | 99        |\n",
      "|    total_timesteps      | 26624     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.66e+14  |\n",
      "|    n_updates            | 120       |\n",
      "|    policy_gradient_loss | -4.74e-07 |\n",
      "|    reward               | 1179361.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.36e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2864179.5434091217\n",
      "Sharpe:  1.0106812593703933\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 271       |\n",
      "|    iterations           | 14        |\n",
      "|    time_elapsed         | 105       |\n",
      "|    total_timesteps      | 28672     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.71e+14  |\n",
      "|    n_updates            | 130       |\n",
      "|    policy_gradient_loss | -7.55e-07 |\n",
      "|    reward               | 1312781.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.27e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3052759.3169661933\n",
      "Sharpe:  1.0685102743086152\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 274       |\n",
      "|    iterations           | 15        |\n",
      "|    time_elapsed         | 112       |\n",
      "|    total_timesteps      | 30720     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.61e+14  |\n",
      "|    n_updates            | 140       |\n",
      "|    policy_gradient_loss | -6.31e-07 |\n",
      "|    reward               | 1356179.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.93e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2973661.1779532013\n",
      "Sharpe:  1.0413862300450154\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 276       |\n",
      "|    iterations           | 16        |\n",
      "|    time_elapsed         | 118       |\n",
      "|    total_timesteps      | 32768     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.76e+14  |\n",
      "|    n_updates            | 150       |\n",
      "|    policy_gradient_loss | -7.47e-07 |\n",
      "|    reward               | 1294504.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.88e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2923535.667245918\n",
      "Sharpe:  1.025388480828823\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 279       |\n",
      "|    iterations           | 17        |\n",
      "|    time_elapsed         | 124       |\n",
      "|    total_timesteps      | 34816     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.57e+14  |\n",
      "|    n_updates            | 160       |\n",
      "|    policy_gradient_loss | -5.23e-07 |\n",
      "|    reward               | 1368808.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.48e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3164256.25901403\n",
      "Sharpe:  1.0976142136105493\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 281       |\n",
      "|    iterations           | 18        |\n",
      "|    time_elapsed         | 131       |\n",
      "|    total_timesteps      | 36864     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.52e+14  |\n",
      "|    n_updates            | 170       |\n",
      "|    policy_gradient_loss | -8.02e-07 |\n",
      "|    reward               | 1387601.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.94e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3110410.652443408\n",
      "Sharpe:  1.0846970029745562\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 283       |\n",
      "|    iterations           | 19        |\n",
      "|    time_elapsed         | 137       |\n",
      "|    total_timesteps      | 38912     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.52e+14  |\n",
      "|    n_updates            | 180       |\n",
      "|    policy_gradient_loss | -6.69e-07 |\n",
      "|    reward               | 1444936.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.93e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2908951.10416969\n",
      "Sharpe:  1.0221071451582056\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 284       |\n",
      "|    iterations           | 20        |\n",
      "|    time_elapsed         | 143       |\n",
      "|    total_timesteps      | 40960     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.64e+14  |\n",
      "|    n_updates            | 190       |\n",
      "|    policy_gradient_loss | -6.99e-07 |\n",
      "|    reward               | 1396178.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.7e+14   |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2901269.986513471\n",
      "Sharpe:  1.0166108457146965\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 286       |\n",
      "|    iterations           | 21        |\n",
      "|    time_elapsed         | 150       |\n",
      "|    total_timesteps      | 43008     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.54e+14  |\n",
      "|    n_updates            | 200       |\n",
      "|    policy_gradient_loss | -6.02e-07 |\n",
      "|    reward               | 1477026.1 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.18e+14  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2724026.974905489\n",
      "Sharpe:  0.9661261669744073\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 287       |\n",
      "|    iterations           | 22        |\n",
      "|    time_elapsed         | 156       |\n",
      "|    total_timesteps      | 45056     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.48e+14  |\n",
      "|    n_updates            | 210       |\n",
      "|    policy_gradient_loss | -8.26e-07 |\n",
      "|    reward               | 1587969.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.84e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3029110.034587809\n",
      "Sharpe:  1.0668483180777524\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 289       |\n",
      "|    iterations           | 23        |\n",
      "|    time_elapsed         | 162       |\n",
      "|    total_timesteps      | 47104     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.22e+14  |\n",
      "|    n_updates            | 220       |\n",
      "|    policy_gradient_loss | -6.94e-07 |\n",
      "|    reward               | 1593681.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.6e+14   |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2840491.999290761\n",
      "Sharpe:  1.0035120051263602\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 290       |\n",
      "|    iterations           | 24        |\n",
      "|    time_elapsed         | 169       |\n",
      "|    total_timesteps      | 49152     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.19e-07  |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.56e+14  |\n",
      "|    n_updates            | 230       |\n",
      "|    policy_gradient_loss | -6.73e-07 |\n",
      "|    reward               | 1667211.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.51e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3004187.998804428\n",
      "Sharpe:  1.0554532065924915\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 291       |\n",
      "|    iterations           | 25        |\n",
      "|    time_elapsed         | 175       |\n",
      "|    total_timesteps      | 51200     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.19e+14  |\n",
      "|    n_updates            | 240       |\n",
      "|    policy_gradient_loss | -7.82e-07 |\n",
      "|    reward               | 1751460.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.64e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3024417.152296054\n",
      "Sharpe:  1.0612738809269324\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 292       |\n",
      "|    iterations           | 26        |\n",
      "|    time_elapsed         | 181       |\n",
      "|    total_timesteps      | 53248     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.83e+14  |\n",
      "|    n_updates            | 250       |\n",
      "|    policy_gradient_loss | -6.83e-07 |\n",
      "|    reward               | 1744181.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.28e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2883413.923406128\n",
      "Sharpe:  1.0189312339814998\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 293       |\n",
      "|    iterations           | 27        |\n",
      "|    time_elapsed         | 188       |\n",
      "|    total_timesteps      | 55296     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.81e+14  |\n",
      "|    n_updates            | 260       |\n",
      "|    policy_gradient_loss | -6.92e-07 |\n",
      "|    reward               | 1937010.4 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.82e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3216389.448758897\n",
      "Sharpe:  1.1104465785521318\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 294       |\n",
      "|    iterations           | 28        |\n",
      "|    time_elapsed         | 194       |\n",
      "|    total_timesteps      | 57344     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 2.38e-07  |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.67e+14  |\n",
      "|    n_updates            | 270       |\n",
      "|    policy_gradient_loss | -6.37e-07 |\n",
      "|    reward               | 1758903.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.28e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2841012.0508804847\n",
      "Sharpe:  1.0006444236505225\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 295       |\n",
      "|    iterations           | 29        |\n",
      "|    time_elapsed         | 201       |\n",
      "|    total_timesteps      | 59392     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 5.45e+14  |\n",
      "|    n_updates            | 280       |\n",
      "|    policy_gradient_loss | -9.96e-07 |\n",
      "|    reward               | 1811201.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.04e+15  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2937430.2969116457\n",
      "Sharpe:  1.0356821771404716\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 295       |\n",
      "|    iterations           | 30        |\n",
      "|    time_elapsed         | 207       |\n",
      "|    total_timesteps      | 61440     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.28e+14  |\n",
      "|    n_updates            | 290       |\n",
      "|    policy_gradient_loss | -5.86e-07 |\n",
      "|    reward               | 1968238.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.74e+14  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3104165.1854754565\n",
      "Sharpe:  1.084361196088504\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 296       |\n",
      "|    iterations           | 31        |\n",
      "|    time_elapsed         | 214       |\n",
      "|    total_timesteps      | 63488     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 5.02e+14  |\n",
      "|    n_updates            | 300       |\n",
      "|    policy_gradient_loss | -7.93e-07 |\n",
      "|    reward               | 1847875.8 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.29e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2761838.5087171164\n",
      "Sharpe:  0.9760095667152887\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 296       |\n",
      "|    iterations           | 32        |\n",
      "|    time_elapsed         | 220       |\n",
      "|    total_timesteps      | 65536     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.79e+14  |\n",
      "|    n_updates            | 310       |\n",
      "|    policy_gradient_loss | -7.66e-07 |\n",
      "|    reward               | 2043698.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.53e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3059574.479908331\n",
      "Sharpe:  1.064899512539861\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 297       |\n",
      "|    iterations           | 33        |\n",
      "|    time_elapsed         | 227       |\n",
      "|    total_timesteps      | 67584     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.11e+14  |\n",
      "|    n_updates            | 320       |\n",
      "|    policy_gradient_loss | -6.97e-07 |\n",
      "|    reward               | 2118495.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 8.59e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3061236.8739848356\n",
      "Sharpe:  1.0710545329086611\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 297       |\n",
      "|    iterations           | 34        |\n",
      "|    time_elapsed         | 233       |\n",
      "|    total_timesteps      | 69632     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.84e+14  |\n",
      "|    n_updates            | 330       |\n",
      "|    policy_gradient_loss | -7.6e-07  |\n",
      "|    reward               | 2107417.0 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.5e+14   |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3033808.6410673703\n",
      "Sharpe:  1.058370658033612\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 298       |\n",
      "|    iterations           | 35        |\n",
      "|    time_elapsed         | 240       |\n",
      "|    total_timesteps      | 71680     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.57e+14  |\n",
      "|    n_updates            | 340       |\n",
      "|    policy_gradient_loss | -5.3e-07  |\n",
      "|    reward               | 2145459.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.74e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2933120.5863819085\n",
      "Sharpe:  1.0309305966816362\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 298       |\n",
      "|    iterations           | 36        |\n",
      "|    time_elapsed         | 247       |\n",
      "|    total_timesteps      | 73728     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 1.79e-07  |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.43e+14  |\n",
      "|    n_updates            | 350       |\n",
      "|    policy_gradient_loss | -6.27e-07 |\n",
      "|    reward               | 2218264.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.45e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3061715.355050583\n",
      "Sharpe:  1.0719746345778622\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 298       |\n",
      "|    iterations           | 37        |\n",
      "|    time_elapsed         | 253       |\n",
      "|    total_timesteps      | 75776     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 0         |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.57e+14  |\n",
      "|    n_updates            | 360       |\n",
      "|    policy_gradient_loss | -8.55e-07 |\n",
      "|    reward               | 2169659.2 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.29e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3029437.3062253674\n",
      "Sharpe:  1.0602811850366434\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 298       |\n",
      "|    iterations           | 38        |\n",
      "|    time_elapsed         | 260       |\n",
      "|    total_timesteps      | 77824     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -1.19e-07 |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.86e+14  |\n",
      "|    n_updates            | 370       |\n",
      "|    policy_gradient_loss | -7.07e-07 |\n",
      "|    reward               | 2269736.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.69e+14  |\n",
      "---------------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3218712.195989274\n",
      "Sharpe:  1.1171407436757308\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 299       |\n",
      "|    iterations           | 39        |\n",
      "|    time_elapsed         | 267       |\n",
      "|    total_timesteps      | 79872     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | -2.38e-07 |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.62e+14  |\n",
      "|    n_updates            | 380       |\n",
      "|    policy_gradient_loss | -9.06e-07 |\n",
      "|    reward               | 1981335.9 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 9.82e+14  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2965487.2393724946\n",
      "Sharpe:  1.0393963401365947\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 299       |\n",
      "|    iterations           | 40        |\n",
      "|    time_elapsed         | 273       |\n",
      "|    total_timesteps      | 81920     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0       |\n",
      "|    clip_fraction        | 0         |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -41.1     |\n",
      "|    explained_variance   | 5.96e-08  |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 4.49e+14  |\n",
      "|    n_updates            | 390       |\n",
      "|    policy_gradient_loss | -8.63e-07 |\n",
      "|    reward               | 2211395.5 |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 1.01e+15  |\n",
      "---------------------------------------\n",
      "{'batch_size': 128, 'buffer_size': 50000, 'learning_rate': 0.001}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg\\ddpg_1\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2951081.659007067\n",
      "Sharpe:  1.0485404546896482\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2883784.997433327\n",
      "Sharpe:  1.0519063965750735\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2883784.997433327\n",
      "Sharpe:  1.0519063965750735\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2883784.997433327\n",
      "Sharpe:  1.0519063965750735\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 0         |\n",
      "|    time_elapsed    | 12375     |\n",
      "|    total_timesteps | 8044      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -3.73e+07 |\n",
      "|    critic_loss     | 1.39e+12  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 6033      |\n",
      "|    reward          | 2883785.0 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2883784.997433327\n",
      "Sharpe:  1.0519063965750735\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2883784.997433327\n",
      "Sharpe:  1.0519063965750735\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2883784.997433327\n",
      "Sharpe:  1.0519063965750735\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2883784.997433327\n",
      "Sharpe:  1.0519063965750735\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 0         |\n",
      "|    time_elapsed    | 61641     |\n",
      "|    total_timesteps | 16088     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -8.23e+07 |\n",
      "|    critic_loss     | 5.84e+12  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 14077     |\n",
      "|    reward          | 2883785.0 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2883784.997433327\n",
      "Sharpe:  1.0519063965750735\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2883784.997433327\n",
      "Sharpe:  1.0519063965750735\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2883784.997433327\n",
      "Sharpe:  1.0519063965750735\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2883784.997433327\n",
      "Sharpe:  1.0519063965750735\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 0         |\n",
      "|    time_elapsed    | 61954     |\n",
      "|    total_timesteps | 24132     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.12e+08 |\n",
      "|    critic_loss     | 9.31e+12  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 22121     |\n",
      "|    reward          | 2883785.0 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2883784.997433327\n",
      "Sharpe:  1.0519063965750735\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2883784.997433327\n",
      "Sharpe:  1.0519063965750735\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2883784.997433327\n",
      "Sharpe:  1.0519063965750735\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2883784.997433327\n",
      "Sharpe:  1.0519063965750735\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 0         |\n",
      "|    time_elapsed    | 62273     |\n",
      "|    total_timesteps | 32176     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.32e+08 |\n",
      "|    critic_loss     | 1.1e+13   |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 30165     |\n",
      "|    reward          | 2883785.0 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2883784.997433327\n",
      "Sharpe:  1.0519063965750735\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2883784.997433327\n",
      "Sharpe:  1.0519063965750735\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2883784.997433327\n",
      "Sharpe:  1.0519063965750735\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2883784.997433327\n",
      "Sharpe:  1.0519063965750735\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 20        |\n",
      "|    fps             | 0         |\n",
      "|    time_elapsed    | 77694     |\n",
      "|    total_timesteps | 40220     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.45e+08 |\n",
      "|    critic_loss     | 1.1e+13   |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 38209     |\n",
      "|    reward          | 2883785.0 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2883784.997433327\n",
      "Sharpe:  1.0519063965750735\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2883784.997433327\n",
      "Sharpe:  1.0519063965750735\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2883784.997433327\n",
      "Sharpe:  1.0519063965750735\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2883784.997433327\n",
      "Sharpe:  1.0519063965750735\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 24        |\n",
      "|    fps             | 0         |\n",
      "|    time_elapsed    | 78122     |\n",
      "|    total_timesteps | 48264     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.53e+08 |\n",
      "|    critic_loss     | 8.09e+12  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 46253     |\n",
      "|    reward          | 2883785.0 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2883784.997433327\n",
      "Sharpe:  1.0519063965750735\n",
      "=================================\n",
      "{'batch_size': 128, 'buffer_size': 100000, 'learning_rate': 0.0003, 'learning_starts': 100, 'ent_coef': 'auto_0.1'}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/sac\\sac_1\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2917190.682178201\n",
      "Sharpe:  1.0239301272179107\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2954927.583153614\n",
      "Sharpe:  1.0362889836868643\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2954949.9758780687\n",
      "Sharpe:  1.036294697613653\n",
      "=================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2954986.5220827595\n",
      "Sharpe:  1.0363058570742523\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 20        |\n",
      "|    time_elapsed    | 397       |\n",
      "|    total_timesteps | 8044      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -5.27e+07 |\n",
      "|    critic_loss     | 1.57e+11  |\n",
      "|    ent_coef        | 1.18      |\n",
      "|    ent_coef_loss   | -31       |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 7943      |\n",
      "|    reward          | 2954986.5 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2955051.0197666064\n",
      "Sharpe:  1.036325458429354\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2954968.2151668547\n",
      "Sharpe:  1.0363075383818263\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2954976.3450252446\n",
      "Sharpe:  1.0363128732965725\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2955360.488219357\n",
      "Sharpe:  1.0364321293843586\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 19        |\n",
      "|    time_elapsed    | 808       |\n",
      "|    total_timesteps | 16088     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -9.17e+07 |\n",
      "|    critic_loss     | 9.06e+11  |\n",
      "|    ent_coef        | 12.1      |\n",
      "|    ent_coef_loss   | -339      |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 15987     |\n",
      "|    reward          | 2955360.5 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2954594.5972491615\n",
      "Sharpe:  1.0362138301798254\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2954849.991005556\n",
      "Sharpe:  1.0362604954782761\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2954958.864332915\n",
      "Sharpe:  1.0363404800554916\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2955529.4547534706\n",
      "Sharpe:  1.036546648902795\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 19        |\n",
      "|    time_elapsed    | 1211      |\n",
      "|    total_timesteps | 24132     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.19e+08 |\n",
      "|    critic_loss     | 1.51e+12  |\n",
      "|    ent_coef        | 116       |\n",
      "|    ent_coef_loss   | -359      |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 24031     |\n",
      "|    reward          | 2955529.5 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2957001.02061544\n",
      "Sharpe:  1.0370135063947596\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2960943.7204188644\n",
      "Sharpe:  1.0382076830356635\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2942187.7447382286\n",
      "Sharpe:  1.0327383143013162\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2941922.4035700588\n",
      "Sharpe:  1.0323995918232443\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 16        |\n",
      "|    fps             | 20        |\n",
      "|    time_elapsed    | 1575      |\n",
      "|    total_timesteps | 32176     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.35e+08 |\n",
      "|    critic_loss     | 2.59e+12  |\n",
      "|    ent_coef        | 926       |\n",
      "|    ent_coef_loss   | -159      |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 32075     |\n",
      "|    reward          | 2941922.5 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2938917.838379632\n",
      "Sharpe:  1.0322174463180296\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2953388.291562038\n",
      "Sharpe:  1.0360374104619416\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2967869.6725440696\n",
      "Sharpe:  1.0411101995919432\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2954001.2661092263\n",
      "Sharpe:  1.0367828452203158\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 20        |\n",
      "|    fps             | 20        |\n",
      "|    time_elapsed    | 1969      |\n",
      "|    total_timesteps | 40220     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.46e+08 |\n",
      "|    critic_loss     | 3.05e+12  |\n",
      "|    ent_coef        | 2.26e+03  |\n",
      "|    ent_coef_loss   | -9.05     |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 40119     |\n",
      "|    reward          | 2954001.2 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2955371.054550409\n",
      "Sharpe:  1.036381005186018\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2937619.5468713655\n",
      "Sharpe:  1.032166613326752\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2957430.4117083233\n",
      "Sharpe:  1.0375081651929774\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2960088.9806171535\n",
      "Sharpe:  1.0390678129748268\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 24        |\n",
      "|    fps             | 20        |\n",
      "|    time_elapsed    | 2379      |\n",
      "|    total_timesteps | 48264     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.49e+08 |\n",
      "|    critic_loss     | 3.94e+12  |\n",
      "|    ent_coef        | 2.46e+03  |\n",
      "|    ent_coef_loss   | 11.2      |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 48163     |\n",
      "|    reward          | 2960089.0 |\n",
      "----------------------------------\n",
      "{'batch_size': 100, 'buffer_size': 1000000, 'learning_rate': 0.001}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/td3\\td3_1\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:3120646.131660948\n",
      "Sharpe:  1.105235521342294\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2929595.6844266555\n",
      "Sharpe:  1.054195361109817\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2929595.6844266555\n",
      "Sharpe:  1.054195361109817\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2929595.6844266555\n",
      "Sharpe:  1.054195361109817\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 4         |\n",
      "|    fps             | 28        |\n",
      "|    time_elapsed    | 282       |\n",
      "|    total_timesteps | 8044      |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -1.99e+07 |\n",
      "|    critic_loss     | 8.82e+11  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 6033      |\n",
      "|    reward          | 2929595.8 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2929595.6844266555\n",
      "Sharpe:  1.054195361109817\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2929595.6844266555\n",
      "Sharpe:  1.054195361109817\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2929595.6844266555\n",
      "Sharpe:  1.054195361109817\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2929595.6844266555\n",
      "Sharpe:  1.054195361109817\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 8         |\n",
      "|    fps             | 26        |\n",
      "|    time_elapsed    | 598       |\n",
      "|    total_timesteps | 16088     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -4.81e+07 |\n",
      "|    critic_loss     | 5.2e+12   |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 14077     |\n",
      "|    reward          | 2929595.8 |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2929595.6844266555\n",
      "Sharpe:  1.054195361109817\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2929595.6844266555\n",
      "Sharpe:  1.054195361109817\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2929595.6844266555\n",
      "Sharpe:  1.054195361109817\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2929595.6844266555\n",
      "Sharpe:  1.054195361109817\n",
      "=================================\n",
      "----------------------------------\n",
      "| time/              |           |\n",
      "|    episodes        | 12        |\n",
      "|    fps             | 26        |\n",
      "|    time_elapsed    | 914       |\n",
      "|    total_timesteps | 24132     |\n",
      "| train/             |           |\n",
      "|    actor_loss      | -7.12e+07 |\n",
      "|    critic_loss     | 8.52e+12  |\n",
      "|    learning_rate   | 0.001     |\n",
      "|    n_updates       | 22121     |\n",
      "|    reward          | 2929595.8 |\n",
      "----------------------------------\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2929595.6844266555\n",
      "Sharpe:  1.054195361109817\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2929595.6844266555\n",
      "Sharpe:  1.054195361109817\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:2929595.6844266555\n",
      "Sharpe:  1.054195361109817\n",
      "=================================\n",
      "Shape of Trade DataFrame:  (7279, 18)\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1000982.8517311376\n",
      "Sharpe:  0.09131372693152327\n",
      "=================================\n",
      "hit end!\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/FinRL-Meta/results/df_daily_return.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1628/3903023208.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[0mdf_daily_return\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m \u001b[0mdf_daily_return\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/FinRL-Meta/results/df_daily_return.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[0mdf_actions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3464\u001b[0m         )\n\u001b[0;32m   3465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3466\u001b[1;33m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[0;32m   3467\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3468\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1103\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         )\n\u001b[1;32m-> 1105\u001b[1;33m         \u001b[0mcsv_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    235\u001b[0m         \"\"\"\n\u001b[0;32m    236\u001b[0m         \u001b[1;31m# apply compression and byte/text conversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m         with get_handle(\n\u001b[0m\u001b[0;32m    238\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/FinRL-Meta/results/df_daily_return.csv'"
     ]
    }
   ],
   "source": [
    "# 5. Implement DRL Algorithms\n",
    "\n",
    "# initialize\n",
    "agent = DRLAgent(env=env_train)\n",
    "\n",
    "# Model 1: A2C\n",
    "agent = DRLAgent(env=env_train)\n",
    "A2C_PARAMS = {\"n_steps\": 5, \"ent_coef\": 0.005, \"learning_rate\": 0.0002}\n",
    "model_a2c = agent.get_model(model_name=\"a2c\", model_kwargs=A2C_PARAMS)\n",
    "trained_a2c = agent.train_model(\n",
    "    model=model_a2c, tb_log_name=\"a2c\", total_timesteps=50000\n",
    ")\n",
    "trained_a2c.save(\"/FinRL-Meta/trained_models/trained_a2c.zip\")\n",
    "\n",
    "# Model 2: PPO\n",
    "agent = DRLAgent(env=env_train)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.005,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo = agent.get_model(\"ppo\", model_kwargs=PPO_PARAMS)\n",
    "trained_ppo = agent.train_model(\n",
    "    model=model_ppo, tb_log_name=\"ppo\", total_timesteps=80000\n",
    ")\n",
    "trained_ppo.save(\"/FinRL-Meta/trained_models/trained_ppo.zip\")\n",
    "\n",
    "# Model 3: DDPG\n",
    "agent = DRLAgent(env=env_train)\n",
    "DDPG_PARAMS = {\"batch_size\": 128, \"buffer_size\": 50000, \"learning_rate\": 0.001}\n",
    "model_ddpg = agent.get_model(\"ddpg\", model_kwargs=DDPG_PARAMS)\n",
    "trained_ddpg = agent.train_model(\n",
    "    model=model_ddpg, tb_log_name=\"ddpg\", total_timesteps=50000\n",
    ")\n",
    "trained_ddpg.save(\"/FinRL-Meta/trained_models/trained_ddpg.zip\")\n",
    "\n",
    "# Model 4: SAC\n",
    "agent = DRLAgent(env=env_train)\n",
    "SAC_PARAMS = {\n",
    "    \"batch_size\": 128,\n",
    "    \"buffer_size\": 100000,\n",
    "    \"learning_rate\": 0.0003,\n",
    "    \"learning_starts\": 100,\n",
    "    \"ent_coef\": \"auto_0.1\",\n",
    "}\n",
    "model_sac = agent.get_model(\"sac\", model_kwargs=SAC_PARAMS)\n",
    "trained_sac = agent.train_model(\n",
    "    model=model_sac, tb_log_name=\"sac\", total_timesteps=50000\n",
    ")\n",
    "trained_sac.save(\"/FinRL-Meta/trained_models/trained_sac.zip\")\n",
    "\n",
    "# Model 5: TD3\n",
    "agent = DRLAgent(env=env_train)\n",
    "TD3_PARAMS = {\"batch_size\": 100, \"buffer_size\": 1000000, \"learning_rate\": 0.001}\n",
    "model_td3 = agent.get_model(\"td3\", model_kwargs=TD3_PARAMS)\n",
    "trained_td3 = agent.train_model(\n",
    "    model=model_td3, tb_log_name=\"td3\", total_timesteps=30000\n",
    ")\n",
    "trained_td3.save(\"/FinRL-Meta/trained_models/trained_td3.zip\")\n",
    "\n",
    "# Trading\n",
    "trade = dp.data_split(df, \"2018-01-01\", \"2019-01-01\")\n",
    "e_trade_gym = StockPortfolioEnv(df=trade, **env_kwargs)\n",
    "\n",
    "print(\"Shape of Trade DataFrame: \", trade.shape)\n",
    "\n",
    "df_daily_return, df_actions = DRLAgent.DRL_prediction(\n",
    "    model=trained_a2c, environment=e_trade_gym\n",
    ")\n",
    "\n",
    "df_daily_return.head()\n",
    "\n",
    "df_daily_return.to_csv(\"/FinRL-Meta/results/df_daily_return.csv\")\n",
    "\n",
    "df_actions.head()\n",
    "\n",
    "df_actions.to_csv(\"/FinRL-Meta/results/df_actions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============DRL Strategy Stats===========\n",
      "==============Get Baseline Stats===========\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (250, 8)\n",
      "Annual return         -0.071511\n",
      "Cumulative returns    -0.070964\n",
      "Annual volatility      0.179326\n",
      "Sharpe ratio          -0.325705\n",
      "Calmar ratio          -0.380947\n",
      "Stability              0.001178\n",
      "Max drawdown          -0.187719\n",
      "Omega ratio            0.943841\n",
      "Sortino ratio         -0.427754\n",
      "Skew                        NaN\n",
      "Kurtosis                    NaN\n",
      "Tail ratio             0.742993\n",
      "Daily value at risk   -0.022825\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 6. Backtest Our Strategy\n",
    "\n",
    "# 6.1. BackTestStats\n",
    "from pyfolio import timeseries\n",
    "\n",
    "DRL_strat = convert_daily_return_to_pyfolio_ts(df_daily_return)\n",
    "perf_func = timeseries.perf_stats\n",
    "perf_stats_all = perf_func(\n",
    "    returns=DRL_strat,\n",
    "    factor_returns=DRL_strat,\n",
    "    positions=None,\n",
    "    transactions=None,\n",
    "    turnover_denom=\"AGB\",\n",
    ")\n",
    "\n",
    "print(\"==============DRL Strategy Stats===========\")\n",
    "perf_stats_all\n",
    "\n",
    "# baseline stats\n",
    "print(\"==============Get Baseline Stats===========\")\n",
    "baseline_df = get_baseline(\n",
    "    ticker=\"^DJI\",\n",
    "    start=df_daily_return.loc[0, \"date\"],\n",
    "    end=df_daily_return.loc[len(df_daily_return) - 1, \"date\"],\n",
    ")\n",
    "\n",
    "stats = backtest_stats(baseline_df, value_col_name=\"close\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (965, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\"><th>Start date</th><td colspan=2>2018-01-02</td></tr>\n",
       "    <tr style=\"text-align: right;\"><th>End date</th><td colspan=2>2018-12-31</td></tr>\n",
       "    <tr style=\"text-align: right;\"><th>Total months</th><td colspan=2>11</td></tr>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Backtest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Annual return</th>\n",
       "      <td>0.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cumulative returns</th>\n",
       "      <td>0.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Annual volatility</th>\n",
       "      <td>17.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sharpe ratio</th>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calmar ratio</th>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stability</th>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max drawdown</th>\n",
       "      <td>-16.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Omega ratio</th>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sortino ratio</th>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Skew</th>\n",
       "      <td>-0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kurtosis</th>\n",
       "      <td>3.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tail ratio</th>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daily value at risk</th>\n",
       "      <td>-2.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alpha</th>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beta</th>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.int64' object has no attribute 'to_pydatetime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1628/2484038676.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mpyfolio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplotting\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplotting_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfont_scale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     pyfolio.create_full_tear_sheet(\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mreturns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDRL_strat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbenchmark_rets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbaseline_returns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     )\n",
      "\u001b[1;32mC:\\python310\\lib\\site-packages\\pyfolio\\tears.py\u001b[0m in \u001b[0;36mcreate_full_tear_sheet\u001b[1;34m(returns, positions, transactions, market_data, benchmark_rets, slippage, live_start_date, sector_mappings, bayesian, round_trips, estimate_intraday, hide_positions, cone_std, bootstrap, unadjusted_returns, style_factor_panel, sectors, caps, shares_held, volumes, percentile, turnover_denom, set_context, factor_returns, factor_loadings, pos_in_dollars, header_rows, factor_partitions)\u001b[0m\n\u001b[0;32m    199\u001b[0m                                      positions, transactions)\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m     create_returns_tear_sheet(\n\u001b[0m\u001b[0;32m    202\u001b[0m         \u001b[0mreturns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[0mpositions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpositions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python310\\lib\\site-packages\\pyfolio\\plotting.py\u001b[0m in \u001b[0;36mcall_w_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     52\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcall_w_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python310\\lib\\site-packages\\pyfolio\\tears.py\u001b[0m in \u001b[0;36mcreate_returns_tear_sheet\u001b[1;34m(returns, positions, transactions, live_start_date, cone_std, benchmark_rets, bootstrap, turnover_denom, header_rows, return_fig)\u001b[0m\n\u001b[0;32m    502\u001b[0m                              header_rows=header_rows)\n\u001b[0;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m     \u001b[0mplotting\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow_worst_drawdown_periods\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreturns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    505\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m     \u001b[0mvertical_sections\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m11\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python310\\lib\\site-packages\\pyfolio\\plotting.py\u001b[0m in \u001b[0;36mshow_worst_drawdown_periods\u001b[1;34m(returns, top)\u001b[0m\n\u001b[0;32m   1662\u001b[0m     \"\"\"\n\u001b[0;32m   1663\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1664\u001b[1;33m     \u001b[0mdrawdown_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimeseries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen_drawdown_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreturns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1665\u001b[0m     utils.print_table(\n\u001b[0;32m   1666\u001b[0m         \u001b[0mdrawdown_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Net drawdown in %'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\python310\\lib\\site-packages\\pyfolio\\timeseries.py\u001b[0m in \u001b[0;36mgen_drawdown_table\u001b[1;34m(returns, top)\u001b[0m\n\u001b[0;32m   1006\u001b[0m         df_drawdowns.loc[i, 'Peak date'] = (peak.to_pydatetime()\n\u001b[0;32m   1007\u001b[0m                                             .strftime('%Y-%m-%d'))\n\u001b[1;32m-> 1008\u001b[1;33m         df_drawdowns.loc[i, 'Valley date'] = (valley.to_pydatetime()\n\u001b[0m\u001b[0;32m   1009\u001b[0m                                               .strftime('%Y-%m-%d'))\n\u001b[0;32m   1010\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecovery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.int64' object has no attribute 'to_pydatetime'"
     ]
    }
   ],
   "source": [
    "# 6.2. BackTestPlot\n",
    "import pyfolio\n",
    "\n",
    "baseline_df = get_baseline(\n",
    "    ticker=\"^DJI\", start=df_daily_return.loc[0, \"date\"], end=\"2021-11-01\"\n",
    ")\n",
    "\n",
    "baseline_returns = get_daily_return(baseline_df, value_col_name=\"close\")\n",
    "\n",
    "with pyfolio.plotting.plotting_context(font_scale=1.1):\n",
    "    pyfolio.create_full_tear_sheet(\n",
    "        returns=DRL_strat, benchmark_rets=baseline_returns, set_context=False\n",
    "    )\n",
    "\n",
    "# Min-Variance Portfolio Allocation\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import risk_models\n",
    "\n",
    "unique_tic = trade.tic.unique()\n",
    "unique_trade_date = trade.date.unique()\n",
    "\n",
    "df.head()\n",
    "\n",
    "# Calculate_portfolio_minimum_variance\n",
    "portfolio = pd.DataFrame(index=range(1), columns=unique_trade_date)\n",
    "initial_capital = 1000000\n",
    "portfolio.loc[0, unique_trade_date[0]] = initial_capital\n",
    "\n",
    "for i in range(len(unique_trade_date) - 1):\n",
    "    df_temp = df[df.date == unique_trade_date[i]].reset_index(drop=True)\n",
    "    df_temp_next = df[df.date == unique_trade_date[i + 1]].reset_index(drop=True)\n",
    "    # Sigma = risk_models.sample_cov(df_temp.return_list[0])\n",
    "\n",
    "    # calculate covariance matrix\n",
    "    Sigma = df_temp.return_list[0].cov()\n",
    "\n",
    "    # portfolio allocation\n",
    "    ef_min_var = EfficientFrontier(None, Sigma, weight_bounds=(0, 0.1))\n",
    "\n",
    "    # minimum variance\n",
    "    raw_weights_min_var = ef_min_var.min_volatility()\n",
    "\n",
    "    # get weights\n",
    "    cleaned_weights_min_var = ef_min_var.clean_weights()\n",
    "\n",
    "    # current capital\n",
    "    cap = portfolio.iloc[0, i]\n",
    "\n",
    "    # current cash invested for each stock\n",
    "    current_cash = [element * cap for element in list(cleaned_weights_min_var.values())]\n",
    "\n",
    "    # current held shares\n",
    "    current_shares = list(np.array(current_cash) / np.array(df_temp.close))\n",
    "\n",
    "    # next time period price\n",
    "    next_price = np.array(df_temp_next.close)\n",
    "\n",
    "    ##next_price * current share to calculate next total account value\n",
    "    portfolio.iloc[0, i + 1] = np.dot(current_shares, next_price)\n",
    "\n",
    "portfolio = portfolio.T\n",
    "portfolio.columns = [\"account_value\"]\n",
    "\n",
    "portfolio.head()\n",
    "\n",
    "a2c_cumpod = (df_daily_return.daily_return + 1).cumprod() - 1\n",
    "\n",
    "min_var_cumpod = (portfolio.account_value.pct_change() + 1).cumprod() - 1\n",
    "\n",
    "dji_cumpod = (baseline_returns + 1).cumprod() - 1\n",
    "\n",
    "# Plotly: DRL, Min-Variance, DJIA\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "time_ind = pd.Series(df_daily_return.date)\n",
    "\n",
    "trace0_portfolio = go.Scatter(\n",
    "    x=time_ind, y=a2c_cumpod, mode=\"lines\", name=\"A2C (Portfolio Allocation)\"\n",
    ")\n",
    "\n",
    "trace1_portfolio = go.Scatter(x=time_ind, y=dji_cumpod, mode=\"lines\", name=\"DJIA\")\n",
    "trace2_portfolio = go.Scatter(\n",
    "    x=time_ind, y=min_var_cumpod, mode=\"lines\", name=\"Min-Variance\"\n",
    ")\n",
    "# trace3_portfolio = go.Scatter(x = time_ind, y = ddpg_cumpod, mode = 'lines', name = 'DDPG')\n",
    "# trace4_portfolio = go.Scatter(x = time_ind, y = addpg_cumpod, mode = 'lines', name = 'Adaptive-DDPG')\n",
    "# trace5_portfolio = go.Scatter(x = time_ind, y = min_cumpod, mode = 'lines', name = 'Min-Variance')\n",
    "# trace4 = go.Scatter(x = time_ind, y = addpg_cumpod, mode = 'lines', name = 'Adaptive-DDPG')\n",
    "# trace2 = go.Scatter(x = time_ind, y = portfolio_cost_minv, mode = 'lines', name = 'Min-Variance')\n",
    "# trace3 = go.Scatter(x = time_ind, y = spx_value, mode = 'lines', name = 'SPX')\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(trace0_portfolio)\n",
    "fig.add_trace(trace1_portfolio)\n",
    "fig.add_trace(trace2_portfolio)\n",
    "\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        x=0,\n",
    "        y=1,\n",
    "        traceorder=\"normal\",\n",
    "        font=dict(family=\"sans-serif\", size=15, color=\"black\"),\n",
    "        bgcolor=\"White\",\n",
    "        bordercolor=\"white\",\n",
    "        borderwidth=2,\n",
    "    ),\n",
    ")\n",
    "\n",
    "# fig.update_layout(legend_orientation=\"h\")\n",
    "\n",
    "fig.update_layout(\n",
    "    title={\n",
    "        #'text': \"Cumulative Return using FinRL\",\n",
    "        \"y\": 0.85,\n",
    "        \"x\": 0.5,\n",
    "        \"xanchor\": \"center\",\n",
    "        \"yanchor\": \"top\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# with Transaction cost\n",
    "# fig.update_layout(title =  'Quarterly Trade Date')\n",
    "\n",
    "fig.update_layout(\n",
    "    #    margin=dict(l=20, r=20, t=20, b=20),\n",
    "    paper_bgcolor=\"rgba(1,1,0,0)\",\n",
    "    plot_bgcolor=\"rgba(1, 1, 0, 0)\",\n",
    "    # xaxis_title=\"Date\",\n",
    "    yaxis_title=\"Cumulative Return\",\n",
    "    xaxis={\n",
    "        \"type\": \"date\",\n",
    "        \"tick0\": time_ind[0],\n",
    "        \"tickmode\": \"linear\",\n",
    "        \"dtick\": 86400000.0 * 80,\n",
    "    },\n",
    ")\n",
    "fig.update_xaxes(\n",
    "    showline=True,\n",
    "    linecolor=\"black\",\n",
    "    showgrid=True,\n",
    "    gridwidth=1,\n",
    "    gridcolor=\"LightSteelBlue\",\n",
    "    mirror=True,\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    showline=True,\n",
    "    linecolor=\"black\",\n",
    "    showgrid=True,\n",
    "    gridwidth=1,\n",
    "    gridcolor=\"LightSteelBlue\",\n",
    "    mirror=True,\n",
    ")\n",
    "fig.update_yaxes(zeroline=True, zerolinewidth=1, zerolinecolor=\"LightSteelBlue\")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "7417fcd27c28a163675abd79abfa37f0fb8db54e512f8dd446ceb545439c3f53"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
